{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory:  c:\\Users\\gheith\\OneDrive - ETS\\0 2023 MTI 865 - Apprentissage profind pour la vision par ordinateur\\CleanedGithub\\MTI865-Competition\\Gheith\\Cross_Teaching_CNN_CNN_plus\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "script_path = \"\"\n",
    "try:\n",
    "    os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    for root, dirs, files in os.walk(os.getcwd()):\n",
    "        # Skip 'data' directory and its subdirectories\n",
    "        if \"Data\" in dirs:\n",
    "            dirs.remove(\"Data\")\n",
    "\n",
    "        if \"mainSegmentationChallenge.ipynb\" in files:\n",
    "            script_path = root\n",
    "            break\n",
    "\n",
    "if script_path == \"\":\n",
    "    raise FileNotFoundError(\n",
    "        \"There is a problem in the folder structure.\\nCONTACT gheith.abinader@icloud.com (514)699-5611\"\n",
    "    )\n",
    "\n",
    "os.chdir(script_path)\n",
    "\n",
    "print(\"Current Working Directory: \", os.getcwd())\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220c7dcc-8438-454d-97b1-8e989a7b8f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# put outside of the function for pickeling\n",
    "def worker_init_fn(worker_id):\n",
    "    random.seed(1208 + worker_id)\n",
    "\n",
    "\n",
    "def runTraining():\n",
    "    print(\"-\" * 40)\n",
    "    print(\"~~~~~~~~  Starting the training... ~~~~~~\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    ## DEFINE HYPERPARAMETERS (batch_size > 1)\n",
    "    batch_size = 16\n",
    "    secondaty_batch_size = 8\n",
    "    batch_size_val = 24\n",
    "    base_lr = 0.01  # Learning Rate\n",
    "    max_iterations = 30000\n",
    "\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    mask_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset(\n",
    "        \"train\",\n",
    "        transform=transform,\n",
    "        mask_transform=mask_transform,\n",
    "        augment=False,\n",
    "        equalize=False,\n",
    "    )\n",
    "\n",
    "    total_slices = len(train_set_full)\n",
    "    labeled_slice = 204\n",
    "    print(\n",
    "        \"Total silices is: {}, labeled slices is: {}\".format(\n",
    "            total_slices, labeled_slice\n",
    "        )\n",
    "    )\n",
    "    labeled_idxs = list(range(0, labeled_slice))\n",
    "    unlabeled_idxs = list(range(labeled_slice, total_slices))\n",
    "    batch_sampler = medicalDataLoader.TwoStreamBatchSampler(\n",
    "        labeled_idxs, unlabeled_idxs, batch_size, secondaty_batch_size\n",
    "    )\n",
    "    trainloader = DataLoader(train_set_full, batch_sampler=batch_sampler, num_workers=0)\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset(\n",
    "        \"val\", transform=transform, mask_transform=mask_transform, equalize=False\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size_val,\n",
    "        worker_init_fn=np.random.seed(0),\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName1, modelName2 = \"K3\", \"K5\"\n",
    "    print(\" Model Name1: {}\".format(modelName1))\n",
    "    print(\" Model Name2: {}\".format(modelName2))\n",
    "\n",
    "    # ## CREATION OF YOUR MODEL\n",
    "    UEncK3 = UNetEncoderK3()\n",
    "    UDecK3 = UNetDecoderK3()\n",
    "    UEncK5 = UNetEncoderK5()\n",
    "    UDecK5 = UNetDecoderK5()\n",
    "\n",
    "    print(\n",
    "        \"Total params: {0:,}\".format(\n",
    "            sum(\n",
    "                p.numel()\n",
    "                for p in list(UEncK3.parameters())\n",
    "                + list(UDecK3.parameters())\n",
    "                + list(UEncK5.parameters())\n",
    "                + list(UDecK5.parameters())\n",
    "                if p.requires_grad\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    ce_loss = CrossEntropyLoss()\n",
    "    dice_loss = DiceLoss(4)\n",
    "    softMax = torch.nn.Softmax()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        UEncK3.cuda()\n",
    "        UDecK3.cuda()\n",
    "        UEncK5.cuda()\n",
    "        UDecK5.cuda()\n",
    "        ce_loss.cuda()\n",
    "        dice_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizerK3 = optim.SGD(\n",
    "        list(UEncK3.parameters()) + list(UDecK3.parameters()),\n",
    "        lr=base_lr,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0001,\n",
    "    )\n",
    "    optimizerK5 = optim.SGD(\n",
    "        list(UEncK3.parameters()) + list(UDecK3.parameters()),\n",
    "        lr=base_lr,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0001,\n",
    "    )\n",
    "    lr_schedulerK3 = PolynomialLR(\n",
    "        optimizerK3,\n",
    "        total_iters=max_iterations,  # The number of steps that the scheduler decays the learning rate.\n",
    "        power=1,\n",
    "    )  # The power of the polynomial.\n",
    "    lr_schedulerK5 = PolynomialLR(\n",
    "        optimizerK5,\n",
    "        total_iters=max_iterations,  # The number of steps that the scheduler decays the learning rate.\n",
    "        power=1,\n",
    "    )  # The power of the polynomial.\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    lossTotalValidation = []\n",
    "    Best_loss_val = 1000\n",
    "    BestEpoch = 0\n",
    "    no_improvement_counter = 0\n",
    "\n",
    "    directory = \"Results/Statistics/\" + \"CrossTeachingK3K5\"\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory) == False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    iter_num = 0\n",
    "    max_epoch = max_iterations // len(trainloader) + 1\n",
    "    print(\"{} iterations per epoch\".format(len(trainloader)))\n",
    "    ## START THE TRAINING\n",
    "    ## FOR EACH EPOCH\n",
    "    for epoch_num in range(max_epoch):\n",
    "        UEncK3.train()\n",
    "        UDecK3.train()\n",
    "        UEncK5.train()\n",
    "        UDecK5.train()\n",
    "        lossEpoch = []\n",
    "        num_batches = len(trainloader)\n",
    "        ## FOR EACH BATCH\n",
    "        for i_batch, sampled_batch in enumerate(trainloader):\n",
    "            ### Set to zero all the gradients\n",
    "            optimizerK3.zero_grad()\n",
    "            optimizerK5.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            volume_batch, label_batch = sampled_batch[\"image\"], sampled_batch[\"label\"]\n",
    "            volume_batch, label_batch = volume_batch.cuda(), label_batch.cuda()\n",
    "\n",
    "            ################### Train ###################\n",
    "            # -- The CNN makes its predictions (forward pass)\n",
    "            featuresK3 = UEncK3(volume_batch)\n",
    "            outK3 = UDecK3(featuresK3)\n",
    "            outK3_soft = torch.softmax(outK3, dim=1)\n",
    "            ##\n",
    "            featuresK5 = UEncK5(volume_batch)\n",
    "            outK5 = UDecK5(featuresK5)\n",
    "            outK5_soft = torch.softmax(outK5, dim=1)\n",
    "\n",
    "            # COMPUTE THE LOSS #adapted from https://github.com/HiLab-git/SSL4MIS/blob/master/code/networks/unet.py\n",
    "            superv_ce_lossK3 = ce_loss(outK3[:8], label_batch.squeeze(1)[:8].long())\n",
    "            superv_dice_lossK3 = dice_loss(outK3_soft[:8], label_batch[:8])\n",
    "            supervised_lossK3 = 0.5 * (superv_ce_lossK3 + superv_dice_lossK3)\n",
    "            ##\n",
    "            superv_ce_lossK5 = ce_loss(outK5[:8], label_batch[:8].squeeze(1).long())\n",
    "            superv_dice_lossK5 = dice_loss(outK5_soft[:8], label_batch[:8])\n",
    "            supervised_lossK5 = 0.5 * (superv_ce_lossK5 + superv_dice_lossK5)\n",
    "\n",
    "            pseudo_lblK3 = torch.argmax(outK3_soft[8:].detach(), dim=1, keepdim=False)\n",
    "            pseudo_lblK5 = torch.argmax(outK5_soft[8:].detach(), dim=1, keepdim=False)\n",
    "\n",
    "            pseudo_suprv_lossK3 = dice_loss(outK3_soft[8:], pseudo_lblK3.unsqueeze(1))\n",
    "            pseudo_suprv_lossK5 = dice_loss(outK5_soft[8:], pseudo_lblK5.unsqueeze(1))\n",
    "\n",
    "            consistency_weight = get_current_consistency_weight(iter_num // 150)\n",
    "\n",
    "            K3Loss = supervised_lossK3 + consistency_weight * pseudo_suprv_lossK3\n",
    "            K5Loss = supervised_lossK5 + consistency_weight * pseudo_suprv_lossK5\n",
    "\n",
    "            loss = K3Loss + K5Loss\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizerK3.step()\n",
    "            optimizerK5.step()\n",
    "            lr_schedulerK3.step()\n",
    "            lr_schedulerK5.step()\n",
    "\n",
    "            iter_num = iter_num + 1\n",
    "\n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING\n",
    "            lossEpoch.append(loss.cpu().data.numpy())\n",
    "            printProgressBar(\n",
    "                i_batch + 1,\n",
    "                num_batches,\n",
    "                prefix=\"[Training] Epoch: {} \".format(epoch_num),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, \".format(loss),\n",
    "            )\n",
    "\n",
    "        lossEpoch = np.asarray(lossEpoch)\n",
    "        lossEpoch = lossEpoch.mean()\n",
    "\n",
    "        lossTotalTraining.append(lossEpoch)\n",
    "\n",
    "        printProgressBar(\n",
    "            num_batches,\n",
    "            num_batches,\n",
    "            done=\"[Training] Epoch: {}, LossG: {:.4f}\".format(epoch_num, lossEpoch),\n",
    "        )\n",
    "        # VALIDATION\n",
    "        UEncK3.eval()\n",
    "        UDecK3.eval()\n",
    "        UEncK5.eval()\n",
    "        UDecK5.eval()\n",
    "        lossEpochVal = []\n",
    "        lossEpochVal1 = []\n",
    "        lossEpochVal2 = []\n",
    "        num_batches = len(val_loader)\n",
    "        for i_batch, sampled_batch in enumerate(val_loader):\n",
    "            images, labels = sampled_batch[\"image\"], sampled_batch[\"label\"]\n",
    "            labels = to_var(labels)\n",
    "            images = to_var(images)\n",
    "\n",
    "            featuresK3 = UEncK3(images)\n",
    "            outK3 = UDecK3(featuresK3)\n",
    "\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            CE_loss_value = ce_loss(outK3, segmentation_classes)\n",
    "\n",
    "            predsoft = softMax(outK3)\n",
    "            pred = predsoft.argmax(dim=1)\n",
    "\n",
    "            # Show live view of model segmentation\n",
    "            if not os.path.exists(\"Results/Segmentation1/\"):\n",
    "                os.makedirs(\"Results/Segmentation1/\")\n",
    "            save_image(\n",
    "                torch.cat([pred.view(labels.shape[0], 1, 256, 256).data / 3.0]),\n",
    "                \"Results/Segmentation1/liveview.png\".format(epoch_num),\n",
    "            )\n",
    "\n",
    "            # Dice_loss_value = computeDSC(pred.unsqueeze(1), segmentation_classes.unsqueeze(1))\n",
    "            Dice_loss_value = dice_loss(predsoft, segmentation_classes.unsqueeze(1))\n",
    "\n",
    "            lossTotal = CE_loss_value + Dice_loss_value\n",
    "\n",
    "            lossEpochVal.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(\n",
    "                i_batch + 1,\n",
    "                num_batches,\n",
    "                prefix=\"[Validation] Epoch: {} \".format(epoch_num),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, CE: {:.4f}, Dice: {:.8f}\".format(\n",
    "                    lossTotal, CE_loss_value, Dice_loss_value\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            # SECOND\n",
    "\n",
    "            featuresK5 = UEncK5(images)\n",
    "            outK5 = UDecK5(featuresK5)\n",
    "\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            CE_loss_value = ce_loss(outK5, segmentation_classes)\n",
    "\n",
    "            predsoft = softMax(outK5)\n",
    "            pred = predsoft.argmax(dim=1)\n",
    "\n",
    "            # Show live view of model segmentation\n",
    "            if not os.path.exists(\"Results/Segmentation2/\"):\n",
    "                os.makedirs(\"Results/Segmentation2/\")\n",
    "            save_image(\n",
    "                torch.cat([pred.view(labels.shape[0], 1, 256, 256).data / 3.0]),\n",
    "                \"Results/Segmentation2/liveview.png\".format(epoch_num),\n",
    "            )\n",
    "\n",
    "            # Dice_loss_value = computeDSC(pred.unsqueeze(1), segmentation_classes.unsqueeze(1))\n",
    "            Dice_loss_value = dice_loss(predsoft, segmentation_classes.unsqueeze(1))\n",
    "\n",
    "            lossTotal = CE_loss_value + Dice_loss_value\n",
    "\n",
    "            lossEpochVal.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(\n",
    "                i_batch + 1,\n",
    "                num_batches,\n",
    "                prefix=\"[Validation] Epoch: {} \".format(epoch_num),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, CE: {:.4f}, Dice: {:.8f}\".format(\n",
    "                    lossTotal, CE_loss_value, Dice_loss_value\n",
    "                ),\n",
    "            )\n",
    "        # Save the model if it is the best so far\n",
    "        modelName = modelName1\n",
    "        lossEpochVal = lossEpochVal1\n",
    "        modelStateDict = {\"ENC\": UEncK3.state_dict(), \"DEC\": UDecK3.state_dict()}\n",
    "        if lossEpochVal2 < lossEpochVal1:\n",
    "            modelName = modelName2\n",
    "            lossEpochVal = lossEpochVal2\n",
    "            modelStateDict = {\"ENC\": UEncK5.state_dict(), \"DEC\": UDecK5.state_dict()}\n",
    "\n",
    "        lossEpochVal = np.asarray(lossEpochVal)\n",
    "        lossEpochVal = lossEpochVal.mean()\n",
    "\n",
    "        lossTotalValidation.append(lossEpochVal)\n",
    "\n",
    "        printProgressBar(\n",
    "            num_batches,\n",
    "            num_batches,\n",
    "            done=\"[Validation] Epoch: {}, LossG: {:.4f}\".format(epoch_num, lossEpochVal),\n",
    "        )\n",
    "\n",
    "        if lossEpochVal < Best_loss_val:\n",
    "            Best_loss_val = lossEpochVal\n",
    "            BestEpoch = epoch_num\n",
    "            no_improvement_counter = 0\n",
    "\n",
    "            if not os.path.exists(\"./models/\" + modelName):\n",
    "                os.makedirs(\"./models/\" + modelName)\n",
    "            torch.save(modelStateDict, \"./models/\" + modelName + \"/\" + str(epoch_num) + \"_Epoch\")\n",
    "            print(\"Best model saved at epoch {}\".format(epoch_num))\n",
    "        else:\n",
    "            no_improvement_counter = no_improvement_counter + 1\n",
    "            print(\n",
    "                \"No improvement in last epoch. Counter: {}\".format(no_improvement_counter))\n",
    "            \n",
    "            if no_improvement_counter % 3 == 0 and no_improvement_counter != 0:\n",
    "                print(\"No improvement in last 3 epochs.\")\n",
    "                # lr = lr/10\n",
    "                # optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "            if epoch_num - BestEpoch > 7:\n",
    "                print(\"No improvement in last 7 epochs. Stopping training.\")\n",
    "                break\n",
    "\n",
    "    np.save(os.path.join(directory, \"Losses.npy\"), lossTotalTraining)\n",
    "    np.save(os.path.join(directory, \"Losses_val.npy\"), lossTotalValidation)\n",
    "\n",
    "    print(\"Training finished. Best model saved at epoch {}\".format(BestEpoch))\n",
    "\n",
    "    graphLosses(lossTotalTraining, lossTotalValidation, modelName, directory)\n",
    "\n",
    "    return BestEpoch\n",
    "\n",
    "    # ## THIS IS HOW YOU WILL SAVE THE TRAINED MODELS AFTER EACH EPOCH.\n",
    "    #     ## WARNING!!!!! YOU DON'T WANT TO SAVE IT AT EACH EPOCH, BUT ONLY WHEN THE MODEL WORKS BEST ON THE VALIDATION SET!!\n",
    "    #     if not os.path.exists('./models/' + modelName):\n",
    "    #             os.makedirs('./models/' + modelName)\n",
    "\n",
    "    #         torch.save(net.state_dict(), './models/' + modelName + '/' + str(i) + '_Epoch')\n",
    "\n",
    "    #     np.save(os.path.join(directory, 'Losses.npy'), lossTotalTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f81713-4c18-4dd3-bc72-35dd8f30a339",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      "Total silices is: 1208, labeled slices is: 204\n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name1: K3\n",
      " Model Name2: K5\n",
      "Total params: 6,766,344\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "25 iterations per epoch\n",
      "[Training] Epoch: 0 [DONE]                                 \n",
      "[Training] Epoch: 0, LossG: 1.6998                                                                           \n",
      "[Validation] Epoch: 0 [DONE]                                                             \n",
      "[Validation] Epoch: 0 [DONE]                                                             \n",
      "[Validation] Epoch: 0, LossG: nan                                                                            \n",
      "No improvement in last epoch. Counter: 1\n",
      "[Training] Epoch: 1 [DONE]                                 \n",
      "[Training] Epoch: 1, LossG: 1.5756                                                                           \n",
      "[Validation] Epoch: 1 [DONE]                                                             \n",
      "[Validation] Epoch: 1 [DONE]                                                             \n",
      "[Validation] Epoch: 1, LossG: nan                                                                            \n",
      "No improvement in last epoch. Counter: 2\n",
      "[Training] Epoch: 2 [=>             ] 8.0% Loss: 1.5735, "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gheith\\OneDrive - ETS\\0 2023 MTI 865 - Apprentissage profind pour la vision par ordinateur\\CleanedGithub\\MTI865-Competition\\Gheith\\Cross_Teaching_CNN_CNN_plus\\mainSegmentationChallenge.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m runTraining()\n",
      "\u001b[1;32mc:\\Users\\gheith\\OneDrive - ETS\\0 2023 MTI 865 - Apprentissage profind pour la vision par ordinateur\\CleanedGithub\\MTI865-Competition\\Gheith\\Cross_Teaching_CNN_CNN_plus\\mainSegmentationChallenge.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=164'>165</a>\u001b[0m \u001b[39m# COMPUTE THE LOSS #adapted from https://github.com/HiLab-git/SSL4MIS/blob/master/code/networks/unet.py\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=165'>166</a>\u001b[0m superv_ce_lossK3 \u001b[39m=\u001b[39m ce_loss(outK3[:\u001b[39m8\u001b[39m], label_batch\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)[:\u001b[39m8\u001b[39m]\u001b[39m.\u001b[39mlong())\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=166'>167</a>\u001b[0m superv_dice_lossK3 \u001b[39m=\u001b[39m dice_loss(outK3_soft[:\u001b[39m8\u001b[39;49m], label_batch[:\u001b[39m8\u001b[39;49m])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=167'>168</a>\u001b[0m supervised_lossK3 \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (superv_ce_lossK3 \u001b[39m+\u001b[39m superv_dice_lossK3)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=168'>169</a>\u001b[0m \u001b[39m##\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gheith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gheith\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gheith\\OneDrive - ETS\\0 2023 MTI 865 - Apprentissage profind pour la vision par ordinateur\\CleanedGithub\\MTI865-Competition\\Gheith\\Cross_Teaching_CNN_CNN_plus\\utils.py:52\u001b[0m, in \u001b[0;36mDiceLoss.forward\u001b[1;34m(self, inputs, target, weight, softmax)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes):\n\u001b[0;32m     51\u001b[0m     dice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dice_loss(inputs[:, i], target[:, i])\n\u001b[1;32m---> 52\u001b[0m     class_wise_dice\u001b[39m.\u001b[39mappend(\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m dice\u001b[39m.\u001b[39;49mitem())\n\u001b[0;32m     53\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m dice \u001b[39m*\u001b[39m weight[i]\n\u001b[0;32m     54\u001b[0m \u001b[39mreturn\u001b[39;00m loss \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae10184-bacf-4c4d-9767-3272a76a0052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
