{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory:  c:\\Users\\gheith\\OneDrive - ETS\\0 2023 MTI 865 - Apprentissage profind pour la vision par ordinateur\\CleanedGithub\\MTI865-Competition\\Gheith\\Cross_Teaching_CNN_CNN_plus\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "script_path = \"\"\n",
    "try:\n",
    "    os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    for root, dirs, files in os.walk(os.getcwd()):\n",
    "        # Skip 'data' directory and its subdirectories\n",
    "        if \"Data\" in dirs:\n",
    "            dirs.remove(\"Data\")\n",
    "\n",
    "        if \"mainSegmentationChallenge.ipynb\" in files:\n",
    "            script_path = root\n",
    "            break\n",
    "\n",
    "if script_path == \"\":\n",
    "    raise FileNotFoundError(\n",
    "        \"There is a problem in the folder structure.\\nCONTACT gheith.abinader@icloud.com (514)699-5611\"\n",
    "    )\n",
    "\n",
    "os.chdir(script_path)\n",
    "\n",
    "print(\"Current Working Directory: \", os.getcwd())\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "220c7dcc-8438-454d-97b1-8e989a7b8f06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# put outside of the function for pickeling\n",
    "def worker_init_fn(worker_id):\n",
    "    random.seed(1208 + worker_id)\n",
    "\n",
    "\n",
    "def runTraining():\n",
    "    print(\"-\" * 40)\n",
    "    print(\"~~~~~~~~  Starting the training... ~~~~~~\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    ## DEFINE HYPERPARAMETERS (batch_size > 1)\n",
    "    batch_size = 16\n",
    "    secondaty_batch_size = 8\n",
    "    batch_size_val = 24\n",
    "    base_lr = 0.01  # Learning Rate\n",
    "    max_iterations = 30000\n",
    "\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    mask_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset(\n",
    "        \"train\",\n",
    "        transform=transform,\n",
    "        mask_transform=mask_transform,\n",
    "        augment=False,\n",
    "        equalize=False,\n",
    "    )\n",
    "\n",
    "    total_slices = len(train_set_full)\n",
    "    labeled_slice = 204\n",
    "    print(\n",
    "        \"Total silices is: {}, labeled slices is: {}\".format(\n",
    "            total_slices, labeled_slice\n",
    "        )\n",
    "    )\n",
    "    labeled_idxs = list(range(0, labeled_slice))\n",
    "    unlabeled_idxs = list(range(labeled_slice, total_slices))\n",
    "    batch_sampler = medicalDataLoader.TwoStreamBatchSampler(\n",
    "        labeled_idxs, unlabeled_idxs, batch_size, secondaty_batch_size\n",
    "    )\n",
    "    trainloader = DataLoader(train_set_full, batch_sampler=batch_sampler, num_workers=0)\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset(\n",
    "        \"val\", transform=transform, mask_transform=mask_transform, equalize=False\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size_val,\n",
    "        worker_init_fn=np.random.seed(0),\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName1, modelName2 = \"K3\", \"K5\"\n",
    "    print(\" Model Name1: {}\".format(modelName1))\n",
    "    print(\" Model Name2: {}\".format(modelName2))\n",
    "\n",
    "    # ## CREATION OF YOUR MODEL\n",
    "    UEncK3 = UNetEncoderK3()\n",
    "    UDecK3 = UNetDecoderK3()\n",
    "    UEncK5 = UNetEncoderK5()\n",
    "    UDecK5 = UNetDecoderK5()\n",
    "\n",
    "    print(\n",
    "        \"Total params: {0:,}\".format(\n",
    "            sum(\n",
    "                p.numel()\n",
    "                for p in list(UEncK3.parameters())\n",
    "                + list(UDecK3.parameters())\n",
    "                + list(UEncK5.parameters())\n",
    "                + list(UDecK5.parameters())\n",
    "                if p.requires_grad\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    ce_loss = CrossEntropyLoss()\n",
    "    dice_loss = DiceLoss(4)\n",
    "    softMax = torch.nn.Softmax()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        UEncK3.cuda()\n",
    "        UDecK3.cuda()\n",
    "        UEncK5.cuda()\n",
    "        UDecK5.cuda()\n",
    "        ce_loss.cuda()\n",
    "        dice_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizerK3 = optim.SGD(\n",
    "        list(UEncK3.parameters()) + list(UDecK3.parameters()),\n",
    "        lr=base_lr,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0001,\n",
    "    )\n",
    "    optimizerK5 = optim.SGD(\n",
    "        list(UEncK3.parameters()) + list(UDecK3.parameters()),\n",
    "        lr=base_lr,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0001,\n",
    "    )\n",
    "    lr_schedulerK3 = PolynomialLR(\n",
    "        optimizerK3,\n",
    "        total_iters=max_iterations,  # The number of steps that the scheduler decays the learning rate.\n",
    "        power=1,\n",
    "    )  # The power of the polynomial.\n",
    "    lr_schedulerK5 = PolynomialLR(\n",
    "        optimizerK5,\n",
    "        total_iters=max_iterations,  # The number of steps that the scheduler decays the learning rate.\n",
    "        power=1,\n",
    "    )  # The power of the polynomial.\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    lossTotalValidation = []\n",
    "    Best_loss_val = 1000\n",
    "    BestEpoch = 0\n",
    "    no_improvement_counter = 0\n",
    "\n",
    "    directory = \"Results/Statistics/\" + \"CrossTeachingK3K5\"\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory) == False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    iter_num = 0\n",
    "    max_epoch = max_iterations // len(trainloader) + 1\n",
    "    print(\"{} iterations per epoch\".format(len(trainloader)))\n",
    "    ## START THE TRAINING\n",
    "    ## FOR EACH EPOCH\n",
    "    for epoch_num in range(max_epoch):\n",
    "        UEncK3.train()\n",
    "        UDecK3.train()\n",
    "        UEncK5.train()\n",
    "        UDecK5.train()\n",
    "        lossEpoch = []\n",
    "        num_batches = len(trainloader)\n",
    "        ## FOR EACH BATCH\n",
    "        for i_batch, sampled_batch in enumerate(trainloader):\n",
    "            ### Set to zero all the gradients\n",
    "            optimizerK3.zero_grad()\n",
    "            optimizerK5.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            volume_batch, label_batch = sampled_batch[\"image\"], sampled_batch[\"label\"]\n",
    "            volume_batch, label_batch = volume_batch.cuda(), label_batch.cuda()\n",
    "\n",
    "            ################### Train ###################\n",
    "            # -- The CNN makes its predictions (forward pass)\n",
    "            featuresK3 = UEncK3(volume_batch)\n",
    "            outK3 = UDecK3(featuresK3)\n",
    "            outK3_soft = torch.softmax(outK3, dim=1)\n",
    "            ##\n",
    "            featuresK5 = UEncK5(volume_batch)\n",
    "            outK5 = UDecK5(featuresK5)\n",
    "            outK5_soft = torch.softmax(outK5, dim=1)\n",
    "\n",
    "            # COMPUTE THE LOSS #adapted from https://github.com/HiLab-git/SSL4MIS/blob/master/code/networks/unet.py\n",
    "            superv_ce_lossK3 = ce_loss(outK3[:8], label_batch.squeeze(1)[:8].long())\n",
    "            superv_dice_lossK3 = dice_loss(outK3_soft[:8], label_batch[:8])\n",
    "            supervised_lossK3 = 0.5 * (superv_ce_lossK3 + superv_dice_lossK3)\n",
    "            ##\n",
    "            superv_ce_lossK5 = ce_loss(outK5[:8], label_batch[:8].squeeze(1).long())\n",
    "            superv_dice_lossK5 = dice_loss(outK5_soft[:8], label_batch[:8])\n",
    "            supervised_lossK5 = 0.5 * (superv_ce_lossK5 + superv_dice_lossK5)\n",
    "\n",
    "            pseudo_lblK3 = torch.argmax(outK3_soft[8:].detach(), dim=1, keepdim=False)\n",
    "            pseudo_lblK5 = torch.argmax(outK5_soft[8:].detach(), dim=1, keepdim=False)\n",
    "\n",
    "            pseudo_suprv_lossK3 = dice_loss(outK3_soft[8:], pseudo_lblK3.unsqueeze(1))\n",
    "            pseudo_suprv_lossK5 = dice_loss(outK5_soft[8:], pseudo_lblK5.unsqueeze(1))\n",
    "\n",
    "            consistency_weight = get_current_consistency_weight(iter_num // 150)\n",
    "\n",
    "            K3Loss = supervised_lossK3 + consistency_weight * pseudo_suprv_lossK3\n",
    "            K5Loss = supervised_lossK5 + consistency_weight * pseudo_suprv_lossK5\n",
    "\n",
    "            loss = K3Loss + K5Loss\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizerK3.step()\n",
    "            optimizerK5.step()\n",
    "            lr_schedulerK3.step()\n",
    "            lr_schedulerK5.step()\n",
    "\n",
    "            iter_num = iter_num + 1\n",
    "\n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING\n",
    "            lossEpoch.append(loss.cpu().data.numpy())\n",
    "            printProgressBar(\n",
    "                i_batch + 1,\n",
    "                num_batches,\n",
    "                prefix=\"[Training] Epoch: {} \".format(epoch_num),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, \".format(loss),\n",
    "            )\n",
    "            #from the https://github.com/HiLab-git/SSL4MIS/val_2d.py\n",
    "            # EVALUATE BOTH MODELS AND PICK THE BEST ONE\n",
    "            if i_batch>0 and i_batch%200 == 0:\n",
    "                UEncK3.eval()\n",
    "                UDecK3.eval()\n",
    "                UEncK5.eval()\n",
    "                UDecK5.eval()\n",
    "                metric_list_accum = 0.0\n",
    "                for i_batch, sampled_batch in enumerate(val_loader):\n",
    "                    volume_batch, label_batch = sampled_batch[\"image\"], sampled_batch[\"label\"]\n",
    "                    images, labels = images.squeeze(1).cpu().detach().numpy(), labels.squeeze(1).cpu().detach()\n",
    "                    gt_classes = getTargetSegmentation(labels).numpy()\n",
    "                    labels = labels.numpy()\n",
    "                    prediction = np.zeros_like(labels)\n",
    "                    for ind in range(image.shape[0]):\n",
    "                        slice = images[ind, :, :]\n",
    "                        x, y = slice.shape[0], slice.shape[1]\n",
    "                        input = torch.from_numpy(slice).unsqueeze(0).unsqueeze(0).float().cuda()\n",
    "                        with torch.no_grad():\n",
    "                            featuresK3 = UEncK3(input)\n",
    "                            outK3 = UDecK3(featuresK3)\n",
    "                            out = torch.argmax(torch.softmax(outK3, dim=1), dim=1).squeeze(0)\n",
    "                            pred = out.cpu().detach().numpy()\n",
    "                            prediction[ind] = pred\n",
    "                    metric_list=[]\n",
    "                    for i in range(1, 4):\n",
    "                        pred = prediction.copy()\n",
    "                        gt = gt_classes.copy()\n",
    "                        pred[:][pred==i] = 1\n",
    "                        pred[:][pred!=i] = 0\n",
    "                        gt[:][pred==i] = 1\n",
    "                        gt[:][pred!=i] = 0\n",
    "                        metric_list.append(calculate_metric_percase(pred, gt))\n",
    "                    metric_list_accum += np.array(metric_list)\n",
    "                metric_list_accum = metric_list_accum / len(val_loader)\n",
    "                for class_i in range(3):\n",
    "                    print('info/model1_val_{}_dice'.format(class_i+1),\n",
    "                                      metric_list_accum[class_i, 0], iter_num)\n",
    "                    print('info/model1_val_{}_hd95'.format(class_i+1),\n",
    "                                      metric_list_accum[class_i, 1], iter_num)\n",
    "                \n",
    "                performance1 = np.mean(metric_list_accum, axis=0)[0]\n",
    "\n",
    "                mean_hd951 = np.mean(metric_list_accum, axis=0)[1]\n",
    "                print('info/model1_val_mean_dice', performance1, iter_num)\n",
    "                print('info/model1_val_mean_hd95', mean_hd951, iter_num)\n",
    "                # EXIT\n",
    "                UEncK3.train()\n",
    "                UDecK3.train()\n",
    "                UEncK5.train()\n",
    "                UDecK5.train()\n",
    "\n",
    "        lossEpoch = np.asarray(lossEpoch)\n",
    "        lossEpoch = lossEpoch.mean()\n",
    "\n",
    "        lossTotalTraining.append(lossEpoch)\n",
    "\n",
    "        printProgressBar(\n",
    "            num_batches,\n",
    "            num_batches,\n",
    "            done=\"[Training] Epoch: {}, LossG: {:.4f}\".format(epoch_num, lossEpoch),\n",
    "        )\n",
    "        # VALIDATION\n",
    "        UEncK3.eval()\n",
    "        UDecK3.eval()\n",
    "        UEncK5.eval()\n",
    "        UDecK5.eval()\n",
    "        lossEpochVal = []\n",
    "        lossEpochVal1 = []\n",
    "        lossEpochVal2 = []\n",
    "        num_batches = len(val_loader)\n",
    "        for i_batch, sampled_batch in enumerate(val_loader):\n",
    "            images, labels = sampled_batch[\"image\"], sampled_batch[\"label\"]\n",
    "            images, labels = images.squeeze(1).cpu().detach().numpy(), labels.squeeze(1).cpu().detach().numpy()\n",
    "            prediction = np.zeros_like(labels)\n",
    "\n",
    "            for ind in range(images.shape[0]):\n",
    "                slice = images[ind, :, :]\n",
    "                x, y = slice.shape[0], slice.shape[1]\n",
    "                input = torch.from_numpy(slice).unsqueeze(0).unsqueeze(0).float().cuda()\n",
    "                net.eval()\n",
    "                with torch.no_grad():\n",
    "                    out = torch.argmax(torch.softmax(net(input), dim=1), dim=1).squeeze(0)\n",
    "                    out = out.cpu().detach().numpy()\n",
    "                    pred = zoom(out, (x / patch_size[0], y / patch_size[1]), order=0)\n",
    "                    prediction[ind] = pred\n",
    "            \n",
    "            metric_list = []\n",
    "            for i in range(1, classes):\n",
    "                metric_list.append(calculate_metric_percase(\n",
    "                    prediction == i, label == i))\n",
    "\n",
    "            # Show live view of model segmentation\n",
    "            if not os.path.exists(\"Results/Segmentation1/\"):\n",
    "                os.makedirs(\"Results/Segmentation1/\")\n",
    "            save_image(\n",
    "                torch.cat([pred.view(labels.shape[0], 1, 256, 256).data / 3.0]),\n",
    "                \"Results/Segmentation1/liveview.png\".format(epoch_num),\n",
    "            )\n",
    "\n",
    "            # Dice_loss_value = computeDSC(pred.unsqueeze(1), segmentation_classes.unsqueeze(1))\n",
    "            Dice_loss_value = dice_loss(predsoft, labels)\n",
    "\n",
    "            lossTotal = CE_loss_value + Dice_loss_value\n",
    "\n",
    "            lossEpochVal1.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(\n",
    "                i_batch + 1,\n",
    "                num_batches,\n",
    "                prefix=\"[Validation] Epoch: {} \".format(epoch_num),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, CE: {:.4f}, Dice: {:.8f}\".format(\n",
    "                    lossTotal, CE_loss_value, Dice_loss_value\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            # SECOND\n",
    "\n",
    "            featuresK5 = UEncK5(images)\n",
    "            outK5 = UDecK5(featuresK5)\n",
    "\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            CE_loss_value = ce_loss(outK5, labels.squeeze(1).long())\n",
    "\n",
    "            predsoft = softMax(outK5)\n",
    "            pred = predsoft.argmax(dim=1)\n",
    "\n",
    "            # Show live view of model segmentation\n",
    "            if not os.path.exists(\"Results/Segmentation2/\"):\n",
    "                os.makedirs(\"Results/Segmentation2/\")\n",
    "            save_image(\n",
    "                torch.cat([pred.view(labels.shape[0], 1, 256, 256).data / 3.0]),\n",
    "                \"Results/Segmentation2/liveview.png\".format(epoch_num),\n",
    "            )\n",
    "\n",
    "            # Dice_loss_value = computeDSC(pred.unsqueeze(1), segmentation_classes.unsqueeze(1))\n",
    "            Dice_loss_value = dice_loss(predsoft, labels)\n",
    "\n",
    "            lossTotal = CE_loss_value + Dice_loss_value\n",
    "\n",
    "            lossEpochVal2.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(\n",
    "                i_batch + 1,\n",
    "                num_batches,\n",
    "                prefix=\"[Validation] Epoch: {} \".format(epoch_num),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, CE: {:.4f}, Dice: {:.8f}\".format(\n",
    "                    lossTotal, CE_loss_value, Dice_loss_value\n",
    "                ),\n",
    "            )\n",
    "        # Save the model if it is the best so far\n",
    "        modelName = modelName1\n",
    "        lossEpochVal1 = np.asarray(lossEpochVal1)\n",
    "        lossEpochVal1 = lossEpochVal1.mean()\n",
    "        lossEpochVal2 = np.asarray(lossEpochVal2)\n",
    "        lossEpochVal2 = lossEpochVal2.mean()\n",
    "        lossEpochVal = lossEpochVal1\n",
    "        modelStateDict = {\"ENC\": UEncK3.state_dict(), \"DEC\": UDecK3.state_dict()}\n",
    "        print(\"K3: {} K5: {}\".format(lossEpochVal1, lossEpochVal2))\n",
    "        if lossEpochVal2 < lossEpochVal1:\n",
    "            modelName = modelName2\n",
    "            lossEpochVal = lossEpochVal2\n",
    "            modelStateDict = {\"ENC\": UEncK5.state_dict(), \"DEC\": UDecK5.state_dict()}\n",
    "\n",
    "        lossEpochVal = np.asarray(lossEpochVal)\n",
    "        lossEpochVal = lossEpochVal.mean()\n",
    "\n",
    "        lossTotalValidation.append(lossEpochVal)\n",
    "\n",
    "        printProgressBar(\n",
    "            num_batches,\n",
    "            num_batches,\n",
    "            done=\"[Validation] Epoch: {}, LossG: {:.4f}\".format(epoch_num, lossEpochVal),\n",
    "        )\n",
    "\n",
    "        if lossEpochVal < Best_loss_val:\n",
    "            Best_loss_val = lossEpochVal\n",
    "            BestEpoch = epoch_num\n",
    "            no_improvement_counter = 0\n",
    "\n",
    "            if not os.path.exists(\"./models/\" + modelName):\n",
    "                os.makedirs(\"./models/\" + modelName)\n",
    "            torch.save(modelStateDict, \"./models/\" + modelName + \"/\" + str(epoch_num) + \"_Epoch\")\n",
    "            print(\"Best model saved at epoch {}\".format(epoch_num))\n",
    "        else:\n",
    "            no_improvement_counter = no_improvement_counter + 1\n",
    "            print(\n",
    "                \"No improvement in last epoch. Counter: {}\".format(no_improvement_counter))\n",
    "            \n",
    "            if no_improvement_counter % 3 == 0 and no_improvement_counter != 0:\n",
    "                print(\"No improvement in last 3 epochs.\")\n",
    "                new_lr1 = lr_schedulerK3.get_lr()\n",
    "                new_lr2 = lr_schedulerK5.get_lr()\n",
    "                new_lr1 = sum(new_lr1)/len(new_lr1)/10\n",
    "                new_lr2 = sum(new_lr2)/len(new_lr2)/10\n",
    "                optimizerK3 = optim.SGD(\n",
    "                    list(UEncK3.parameters()) + list(UDecK3.parameters()),\n",
    "                    lr=new_lr1,\n",
    "                    momentum=0.9,\n",
    "                    weight_decay=0.0001,\n",
    "                )\n",
    "                optimizerK5 = optim.SGD(\n",
    "                    list(UEncK3.parameters()) + list(UDecK3.parameters()),\n",
    "                    lr=new_lr2,\n",
    "                    momentum=0.9,\n",
    "                    weight_decay=0.0001,\n",
    "                )\n",
    "                lr_schedulerK3 = PolynomialLR(\n",
    "                    optimizerK3,\n",
    "                    total_iters=max_iterations,  # The number of steps that the scheduler decays the learning rate.\n",
    "                    power=1,\n",
    "                )  # The power of the polynomial.\n",
    "                lr_schedulerK5 = PolynomialLR(\n",
    "                    optimizerK5,\n",
    "                    total_iters=max_iterations,  # The number of steps that the scheduler decays the learning rate.\n",
    "                    power=1,\n",
    "                )  # The power of the polynomial.\n",
    "\n",
    "            if epoch_num - BestEpoch > 7:\n",
    "                print(\"No improvement in last 7 epochs. Stopping training.\")\n",
    "                break\n",
    "\n",
    "    np.save(os.path.join(directory, \"Losses.npy\"), lossTotalTraining)\n",
    "    np.save(os.path.join(directory, \"Losses_val.npy\"), lossTotalValidation)\n",
    "\n",
    "    print(\"Training finished. Best model saved at epoch {}\".format(BestEpoch))\n",
    "\n",
    "    graphLosses(lossTotalTraining, lossTotalValidation, modelName, directory)\n",
    "\n",
    "    return BestEpoch\n",
    "\n",
    "    # ## THIS IS HOW YOU WILL SAVE THE TRAINED MODELS AFTER EACH EPOCH.\n",
    "    #     ## WARNING!!!!! YOU DON'T WANT TO SAVE IT AT EACH EPOCH, BUT ONLY WHEN THE MODEL WORKS BEST ON THE VALIDATION SET!!\n",
    "    #     if not os.path.exists('./models/' + modelName):\n",
    "    #             os.makedirs('./models/' + modelName)\n",
    "\n",
    "    #         torch.save(net.state_dict(), './models/' + modelName + '/' + str(i) + '_Epoch')\n",
    "\n",
    "    #     np.save(os.path.join(directory, 'Losses.npy'), lossTotalTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f81713-4c18-4dd3-bc72-35dd8f30a339",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      "Total silices is: 1208, labeled slices is: 204\n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name1: K3\n",
      " Model Name2: K5\n",
      "Total params: 6,766,344\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "25 iterations per epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] Epoch: 0 [DONE]                                 \n",
      "[Training] Epoch: 0, LossG: 1.6976                                                                           \n",
      "[Validation] Epoch: 0 [DONE]                                                             \n",
      "[Validation] Epoch: 0 [DONE]                                                             \n",
      "K3: 0.8468537330627441 K5: 2.364774465560913\n",
      "[Validation] Epoch: 0, LossG: 0.8469                                                                         \n",
      "Best model saved at epoch 0\n",
      "[Training] Epoch: 1 [DONE]                                 \n",
      "[Training] Epoch: 1, LossG: 1.5663                                                                           \n",
      "[Validation] Epoch: 1 [DONE]                                                             \n",
      "[Validation] Epoch: 1 [DONE]                                                             \n",
      "K3: 0.8571041822433472 K5: 2.3857994079589844\n",
      "[Validation] Epoch: 1, LossG: 0.8571                                                                         \n",
      "No improvement in last epoch. Counter: 1\n",
      "[Training] Epoch: 2 [DONE]                                 \n",
      "[Training] Epoch: 2, LossG: 1.5350                                                                           \n",
      "[Validation] Epoch: 2 [DONE]                                                             \n",
      "[Validation] Epoch: 2 [DONE]                                                             \n",
      "K3: 0.7431110143661499 K5: 2.3407435417175293\n",
      "[Validation] Epoch: 2, LossG: 0.7431                                                                         \n",
      "Best model saved at epoch 2\n",
      "[Training] Epoch: 3 [DONE]                                 \n",
      "[Training] Epoch: 3, LossG: 1.4882                                                                           \n",
      "[Validation] Epoch: 3 [DONE]                                                             \n",
      "[Validation] Epoch: 3 [DONE]                                                             \n",
      "K3: 0.6425346732139587 K5: 2.3331658840179443\n",
      "[Validation] Epoch: 3, LossG: 0.6425                                                                         \n",
      "Best model saved at epoch 3\n",
      "[Training] Epoch: 4 [DONE]                                 \n",
      "[Training] Epoch: 4, LossG: 1.4677                                                                           \n",
      "[Validation] Epoch: 4 [DONE]                                                             \n",
      "[Validation] Epoch: 4 [DONE]                                                             \n",
      "K3: 0.8410820960998535 K5: 2.3331260681152344\n",
      "[Validation] Epoch: 4, LossG: 0.8411                                                                         \n",
      "No improvement in last epoch. Counter: 1\n",
      "[Training] Epoch: 5 [DONE]                                 \n",
      "[Training] Epoch: 5, LossG: 1.4634                                                                           \n",
      "[Validation] Epoch: 5 [DONE]                                                             \n",
      "[Validation] Epoch: 5 [DONE]                                                             \n",
      "K3: 0.6353839039802551 K5: 2.334519624710083\n",
      "[Validation] Epoch: 5, LossG: 0.6354                                                                         \n",
      "Best model saved at epoch 5\n",
      "[Training] Epoch: 6 [DONE]                                 \n",
      "[Training] Epoch: 6, LossG: 1.4573                                                                           \n",
      "[Validation] Epoch: 6 [DONE]                                                             \n",
      "[Validation] Epoch: 6 [DONE]                                                             \n",
      "K3: 0.6967267394065857 K5: 2.331852436065674\n",
      "[Validation] Epoch: 6, LossG: 0.6967                                                                         \n",
      "No improvement in last epoch. Counter: 1\n",
      "[Training] Epoch: 7 [DONE]                                 \n",
      "[Training] Epoch: 7, LossG: 1.4562                                                                           \n",
      "[Validation] Epoch: 7 [DONE]                                                             \n",
      "[Validation] Epoch: 7 [DONE]                                                             \n",
      "K3: 0.644985556602478 K5: 2.3326921463012695\n",
      "[Validation] Epoch: 7, LossG: 0.6450                                                                         \n",
      "No improvement in last epoch. Counter: 2\n",
      "[Training] Epoch: 8 [DONE]                                 \n",
      "[Training] Epoch: 8, LossG: 1.4551                                                                           \n",
      "[Validation] Epoch: 8 [DONE]                                                             \n",
      "[Validation] Epoch: 8 [DONE]                                                             \n",
      "K3: 0.6095901131629944 K5: 2.3324248790740967\n",
      "[Validation] Epoch: 8, LossG: 0.6096                                                                         \n",
      "Best model saved at epoch 8\n",
      "[Training] Epoch: 9 [DONE]                                 \n",
      "[Training] Epoch: 9, LossG: 1.4497                                                                           \n",
      "[Validation] Epoch: 9 [DONE]                                                             \n",
      "[Validation] Epoch: 9 [DONE]                                                             \n",
      "K3: 0.6266096830368042 K5: 2.3299193382263184\n",
      "[Validation] Epoch: 9, LossG: 0.6266                                                                         \n",
      "No improvement in last epoch. Counter: 1\n",
      "[Training] Epoch: 10 [DONE]                                 \n",
      "[Training] Epoch: 10, LossG: 1.4449                                                                          \n",
      "[Validation] Epoch: 10 [DONE]                                                             \n",
      "[Validation] Epoch: 10 [DONE]                                                             \n",
      "K3: 0.6363555788993835 K5: 2.332716703414917\n",
      "[Validation] Epoch: 10, LossG: 0.6364                                                                        \n",
      "No improvement in last epoch. Counter: 2\n",
      "[Training] Epoch: 11 [DONE]                                 \n",
      "[Training] Epoch: 11, LossG: 1.2229                                                                          \n",
      "[Validation] Epoch: 11 [DONE]                                                             \n",
      "[Validation] Epoch: 11 [DONE]                                                             \n",
      "K3: 0.13678282499313354 K5: 2.331998586654663\n",
      "[Validation] Epoch: 11, LossG: 0.1368                                                                        \n",
      "Best model saved at epoch 11\n",
      "[Training] Epoch: 12 [DONE]                                 \n",
      "[Training] Epoch: 12, LossG: 1.2048                                                                          \n",
      "[Validation] Epoch: 12 [DONE]                                                             \n",
      "[Validation] Epoch: 12 [DONE]                                                             \n",
      "K3: 0.1377105712890625 K5: 2.3325858116149902\n",
      "[Validation] Epoch: 12, LossG: 0.1377                                                                        \n",
      "No improvement in last epoch. Counter: 1\n",
      "[Training] Epoch: 13 [DONE]                                 \n",
      "[Training] Epoch: 13, LossG: 1.2010                                                                          \n",
      "[Validation] Epoch: 13 [DONE]                                                             \n",
      "[Validation] Epoch: 13 [DONE]                                                             \n",
      "K3: 0.1205746978521347 K5: 2.3336989879608154\n",
      "[Validation] Epoch: 13, LossG: 0.1206                                                                        \n",
      "Best model saved at epoch 13\n",
      "[Training] Epoch: 14 [DONE]                                 \n",
      "[Training] Epoch: 14, LossG: 1.2019                                                                          \n",
      "[Validation] Epoch: 14 [DONE]                                                             \n",
      "[Validation] Epoch: 14 [DONE]                                                             \n",
      "K3: 0.16020767390727997 K5: 2.3306875228881836\n",
      "[Validation] Epoch: 14, LossG: 0.1602                                                                        \n",
      "No improvement in last epoch. Counter: 1\n",
      "[Training] Epoch: 15 [DONE]                                 \n",
      "[Training] Epoch: 15, LossG: 1.2005                                                                          \n",
      "[Validation] Epoch: 15 [DONE]                                                             \n",
      "[Validation] Epoch: 15 [DONE]                                                             \n",
      "K3: 0.12344364076852798 K5: 2.333876848220825\n",
      "[Validation] Epoch: 15, LossG: 0.1234                                                                        \n",
      "No improvement in last epoch. Counter: 2\n",
      "[Training] Epoch: 16 [DONE]                                 \n",
      "[Training] Epoch: 16, LossG: 1.1984                                                                          \n",
      "[Validation] Epoch: 16 [DONE]                                                             \n",
      "[Validation] Epoch: 16 [DONE]                                                             \n",
      "K3: 0.12157770991325378 K5: 2.333876609802246\n",
      "[Validation] Epoch: 16, LossG: 0.1216                                                                        \n",
      "No improvement in last epoch. Counter: 3\n",
      "No improvement in last 3 epochs.\n",
      "[Training] Epoch: 17 [DONE]                                 \n",
      "[Training] Epoch: 17, LossG: 1.1967                                                                          \n",
      "[Validation] Epoch: 17 [DONE]                                                             \n",
      "[Validation] Epoch: 17 [DONE]                                                             \n",
      "K3: 0.10058166086673737 K5: 2.3330087661743164\n",
      "[Validation] Epoch: 17, LossG: 0.1006                                                                        \n",
      "Best model saved at epoch 17\n",
      "[Training] Epoch: 18 [DONE]                                 \n",
      "[Training] Epoch: 18, LossG: 1.1961                                                                          \n",
      "[Validation] Epoch: 18 [DONE]                                                             \n",
      "[Validation] Epoch: 18 [DONE]                                                             \n",
      "K3: 0.09747476875782013 K5: 2.332733154296875\n",
      "[Validation] Epoch: 18, LossG: 0.0975                                                                        \n",
      "Best model saved at epoch 18\n",
      "[Training] Epoch: 19 [DONE]                                 \n",
      "[Training] Epoch: 19, LossG: 1.1970                                                                          \n",
      "[Validation] Epoch: 19 [DONE]                                                             \n",
      "[Validation] Epoch: 19 [DONE]                                                             \n",
      "K3: 0.0978197306394577 K5: 2.3359737396240234\n",
      "[Validation] Epoch: 19, LossG: 0.0978                                                                        \n",
      "No improvement in last epoch. Counter: 1\n",
      "[Training] Epoch: 20 [DONE]                                 \n",
      "[Training] Epoch: 20, LossG: 1.1942                                                                          \n",
      "[Validation] Epoch: 20 [DONE]                                                             \n",
      "[Validation] Epoch: 20 [DONE]                                                             \n",
      "K3: 0.09691628813743591 K5: 2.3310394287109375\n",
      "[Validation] Epoch: 20, LossG: 0.0969                                                                        \n",
      "Best model saved at epoch 20\n",
      "[Training] Epoch: 21 [DONE]                                 \n",
      "[Training] Epoch: 21, LossG: 1.1937                                                                          \n",
      "[Validation] Epoch: 21 [DONE]                                                             \n",
      "[Validation] Epoch: 21 [DONE]                                                             \n",
      "K3: 0.09726274013519287 K5: 2.3302786350250244\n",
      "[Validation] Epoch: 21, LossG: 0.0973                                                                        \n",
      "No improvement in last epoch. Counter: 1\n",
      "[Training] Epoch: 22 [DONE]                                 \n",
      "[Training] Epoch: 22, LossG: 1.1960                                                                          \n",
      "[Validation] Epoch: 22 [DONE]                                                             \n",
      "[Validation] Epoch: 22 [DONE]                                                             \n",
      "K3: 0.10087858885526657 K5: 2.336177349090576\n",
      "[Validation] Epoch: 22, LossG: 0.1009                                                                        \n",
      "No improvement in last epoch. Counter: 2\n",
      "[Training] Epoch: 23 [DONE]                                 \n",
      "[Training] Epoch: 23, LossG: 1.1953                                                                          \n",
      "[Validation] Epoch: 23 [DONE]                                                             \n",
      "[Validation] Epoch: 23 [DONE]                                                             \n",
      "K3: 0.10270832479000092 K5: 2.3352866172790527\n",
      "[Validation] Epoch: 23, LossG: 0.1027                                                                        \n",
      "No improvement in last epoch. Counter: 3\n",
      "No improvement in last 3 epochs.\n",
      "[Training] Epoch: 24 [DONE]                                 \n",
      "[Training] Epoch: 24, LossG: 1.1943                                                                          \n",
      "[Validation] Epoch: 24 [DONE]                                                             \n",
      "[Validation] Epoch: 24 [DONE]                                                             \n",
      "K3: 0.10197322815656662 K5: 2.332530975341797\n",
      "[Validation] Epoch: 24, LossG: 0.1020                                                                        \n",
      "No improvement in last epoch. Counter: 4\n",
      "[Training] Epoch: 25 [DONE]                                 \n",
      "[Training] Epoch: 25, LossG: 1.1948                                                                          \n",
      "[Validation] Epoch: 25 [DONE]                                                             \n",
      "[Validation] Epoch: 25 [DONE]                                                             \n",
      "K3: 0.10073384642601013 K5: 2.3331241607666016\n",
      "[Validation] Epoch: 25, LossG: 0.1007                                                                        \n",
      "No improvement in last epoch. Counter: 5\n",
      "[Training] Epoch: 26 [DONE]                                 \n",
      "[Training] Epoch: 26, LossG: 1.1943                                                                          \n",
      "[Validation] Epoch: 26 [DONE]                                                             \n",
      "[Validation] Epoch: 26 [DONE]                                                             \n",
      "K3: 0.10085085034370422 K5: 2.3314144611358643\n",
      "[Validation] Epoch: 26, LossG: 0.1009                                                                        \n",
      "No improvement in last epoch. Counter: 6\n",
      "No improvement in last 3 epochs.\n",
      "[Training] Epoch: 27 [DONE]                                 \n",
      "[Training] Epoch: 27, LossG: 1.1944                                                                          \n",
      "[Validation] Epoch: 27 [DONE]                                                             \n",
      "[Validation] Epoch: 27 [DONE]                                                             \n",
      "K3: 0.10218073427677155 K5: 2.334076404571533\n",
      "[Validation] Epoch: 27, LossG: 0.1022                                                                        \n",
      "No improvement in last epoch. Counter: 7\n",
      "[Training] Epoch: 28 [DONE]                                 \n",
      "[Training] Epoch: 28, LossG: 1.1946                                                                          \n",
      "[Validation] Epoch: 28 [DONE]                                                             \n",
      "[Validation] Epoch: 28 [DONE]                                                             \n",
      "K3: 0.10136683285236359 K5: 2.3324596881866455\n",
      "[Validation] Epoch: 28, LossG: 0.1014                                                                        \n",
      "No improvement in last epoch. Counter: 8\n",
      "No improvement in last 7 epochs. Stopping training.\n",
      "Training finished. Best model saved at epoch 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae10184-bacf-4c4d-9767-3272a76a0052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
