{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory:  c:\\Users\\gheith\\OneDrive - ETS\\0 2023 MTI 865 - Apprentissage profind pour la vision par ordinateur\\CleanedGithub\\MTI865-Competition\\Gheith\\Cross_Teaching_CNN_CNN_plus\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "script_path = \"\"\n",
    "try:\n",
    "    os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    for root, dirs, files in os.walk(os.getcwd()):\n",
    "        # Skip 'data' directory and its subdirectories\n",
    "        if \"Data\" in dirs:\n",
    "            dirs.remove(\"Data\")\n",
    "\n",
    "        if \"mainSegmentationChallenge.ipynb\" in files:\n",
    "            script_path = root\n",
    "            break\n",
    "\n",
    "if script_path == \"\":\n",
    "    raise FileNotFoundError(\n",
    "        \"There is a problem in the folder structure.\\nCONTACT gheith.abinader@icloud.com (514)699-5611\"\n",
    "    )\n",
    "\n",
    "os.chdir(script_path)\n",
    "\n",
    "print(\"Current Working Directory: \", os.getcwd())\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import PolynomialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220c7dcc-8438-454d-97b1-8e989a7b8f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# put outside of the function for pickeling\n",
    "def worker_init_fn(worker_id):\n",
    "    random.seed(1208 + worker_id)\n",
    "\n",
    "\n",
    "def runTraining():\n",
    "    print(\"-\" * 40)\n",
    "    print(\"~~~~~~~~  Starting the training... ~~~~~~\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    ## DEFINE HYPERPARAMETERS (batch_size > 1)\n",
    "    batch_size = 16\n",
    "    secondaty_batch_size = 8\n",
    "    batch_size_val = 24\n",
    "    base_lr = 0.01  # Learning Rate\n",
    "    max_iterations = 30000\n",
    "\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    mask_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset(\n",
    "        \"train\",\n",
    "        transform=transform,\n",
    "        mask_transform=mask_transform,\n",
    "        augment=False,\n",
    "        equalize=False,\n",
    "    )\n",
    "\n",
    "    total_slices = len(train_set_full)\n",
    "    labeled_slice = 204\n",
    "    print(\n",
    "        \"Total silices is: {}, labeled slices is: {}\".format(\n",
    "            total_slices, labeled_slice\n",
    "        )\n",
    "    )\n",
    "    labeled_idxs = list(range(0, labeled_slice))\n",
    "    unlabeled_idxs = list(range(labeled_slice, total_slices))\n",
    "    batch_sampler = medicalDataLoader.TwoStreamBatchSampler(\n",
    "        labeled_idxs, unlabeled_idxs, batch_size, secondaty_batch_size\n",
    "    )\n",
    "    trainloader = DataLoader(train_set_full, batch_sampler=batch_sampler, num_workers=0)\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset(\n",
    "        \"val\", transform=transform, mask_transform=mask_transform, equalize=False\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size_val,\n",
    "        worker_init_fn=np.random.seed(0),\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = \"Test_Model\"\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    # ## CREATION OF YOUR MODEL\n",
    "    UEncK3 = UNetEncoderK3()\n",
    "    UDecK3 = UNetDecoderK3()\n",
    "    UEncK5 = UNetEncoderK5()\n",
    "    UDecK5 = UNetDecoderK5()\n",
    "\n",
    "    print(\n",
    "        \"Total params: {0:,}\".format(\n",
    "            sum(\n",
    "                p.numel()\n",
    "                for p in list(UEncK3.parameters())\n",
    "                + list(UDecK3.parameters())\n",
    "                + list(UEncK5.parameters())\n",
    "                + list(UDecK5.parameters())\n",
    "                if p.requires_grad\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    ce_loss = CrossEntropyLoss()\n",
    "    dice_loss = DiceLoss(4)\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizerK3 = optim.SGD(\n",
    "        list(UEncK3.parameters()) + list(UDecK3.parameters()),\n",
    "        lr=base_lr,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0001,\n",
    "    )\n",
    "    optimizerK5 = optim.SGD(\n",
    "        list(UEncK3.parameters()) + list(UDecK3.parameters()),\n",
    "        lr=base_lr,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0001,\n",
    "    )\n",
    "    lr_schedulerK3 = PolynomialLR(\n",
    "        optimizerK3,\n",
    "        total_iters=max_iterations,  # The number of steps that the scheduler decays the learning rate.\n",
    "        power=1,\n",
    "    )  # The power of the polynomial.\n",
    "    lr_schedulerK5 = PolynomialLR(\n",
    "        optimizerK5,\n",
    "        total_iters=max_iterations,  # The number of steps that the scheduler decays the learning rate.\n",
    "        power=1,\n",
    "    )  # The power of the polynomial.\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    Best_loss_val1 = 1000\n",
    "    Best_loss_val2 = 1000\n",
    "    BestEpoch1 = 0\n",
    "    BestEpoch2 = 0\n",
    "\n",
    "    directory = \"Results/Statistics/\" + \"CrossTeachingK3K5\"\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory) == False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    iter_num = 0\n",
    "    max_epoch = max_iterations // len(trainloader) + 1\n",
    "    print(\"{} iterations per epoch\".format(len(trainloader)))\n",
    "    ## START THE TRAINING\n",
    "    ## FOR EACH EPOCH\n",
    "    for epoch_num in range(max_epoch):\n",
    "        # for epoch_num in range(1):\n",
    "        UEncK3.train()\n",
    "        UDecK3.train()\n",
    "        UEncK5.train()\n",
    "        UDecK5.train()\n",
    "        lossEpoch = []\n",
    "        DSCEpoch = []\n",
    "        DSCEpoch_w = []\n",
    "        num_batches = len(trainloader)\n",
    "        ## FOR EACH BATCH\n",
    "        for i_batch, sampled_batch in enumerate(trainloader):\n",
    "            ### Set to zero all the gradients\n",
    "            optimizerK3.zero_grad()\n",
    "            optimizerK5.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            volume_batch, label_batch = sampled_batch[\"image\"], sampled_batch[\"label\"]\n",
    "            # volume_batch, label_batch = volume_batch.cuda(), label_batch.cuda()\n",
    "\n",
    "            ################### Train ###################\n",
    "            # -- The CNN makes its predictions (forward pass)\n",
    "            featuresK3 = UEncK3(volume_batch)\n",
    "            outK3 = UDecK3(featuresK3)\n",
    "            outK3_soft = torch.softmax(outK3, dim=1)\n",
    "            ##\n",
    "            featuresK5 = UEncK5(volume_batch)\n",
    "            outK5 = UDecK5(featuresK5)\n",
    "            outK5_soft = torch.softmax(outK5, dim=1)\n",
    "\n",
    "            # -- Compute the losses --#\n",
    "            # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "            segmentation_classesK3 = getTargetSegmentation(outK3)\n",
    "            segmentation_classesK5 = getTargetSegmentation(outK5)\n",
    "\n",
    "            # COMPUTE THE LOSS #adapted from https://github.com/HiLab-git/SSL4MIS/blob/master/code/networks/unet.py\n",
    "            superv_ce_lossK3 = ce_loss(outK3[:8], label_batch[:8].long())\n",
    "            superv_dice_lossK3 = dice_loss(outK3_soft[:8], label_batch[:8].unsqueeze(1))\n",
    "            supervised_lossK3 = 0.5 * (superv_ce_lossK3 + superv_dice_lossK3)\n",
    "            ##\n",
    "            superv_ce_lossK5 = ce_loss(outK5[:8], label_batch[:8].long())\n",
    "            superv_dice_lossK5 = dice_loss(outK5_soft[:8], label_batch[:8].unsqueeze(1))\n",
    "            supervised_lossK5 = 0.5 * (superv_ce_lossK5 + superv_dice_lossK5)\n",
    "\n",
    "            pseudo_lblK3 = torch.argmax(outK3_soft[8:].detach(), dim=1, keepdim=False)\n",
    "            pseudo_lblK5 = torch.argmax(outK5_soft[8:].detach(), dim=1, keepdim=False)\n",
    "\n",
    "            pseudo_suprv_lossK3 = dice_loss(outK3_soft[8:], pseudo_lblK3.unsqueeze(1))\n",
    "            pseudo_suprv_lossK5 = dice_loss(outK5_soft[8:], pseudo_lblK5.unsqueeze(1))\n",
    "\n",
    "            consistency_weight = get_current_consistency_weight(iter_num // 150)\n",
    "\n",
    "            K3Loss = supervised_lossK3 + consistency_weight * pseudo_suprv_lossK3\n",
    "            K5Loss = supervised_lossK5 + consistency_weight * pseudo_suprv_lossK5\n",
    "\n",
    "            loss = K3Loss + K5Loss\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizerK3.step()\n",
    "            optimizerK5.step()\n",
    "            lr_schedulerK3.step()\n",
    "            lr_schedulerK5.step()\n",
    "\n",
    "            iter_num = iter_num + 1\n",
    "\n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING\n",
    "            lossEpoch.append(loss.cpu().data.numpy())\n",
    "            printProgressBar(\n",
    "                i_batch + 1,\n",
    "                num_batches,\n",
    "                prefix=\"[Training] Epoch: {} \".format(epoch_num),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, \".format(loss),\n",
    "            )\n",
    "\n",
    "        lossEpoch = np.asarray(lossEpoch)\n",
    "        lossEpoch = lossEpoch.mean()\n",
    "\n",
    "        lossTotalTraining.append(lossEpoch)\n",
    "\n",
    "        printProgressBar(\n",
    "            num_batches,\n",
    "            num_batches,\n",
    "            done=\"[Training] Epoch: {}, LossG: {:.4f}\".format(epoch_num, lossEpoch),\n",
    "        )\n",
    "\n",
    "        ## THIS IS HOW YOU WILL SAVE THE TRAINED MODELS AFTER EACH EPOCH.\n",
    "    #     ## WARNING!!!!! YOU DON'T WANT TO SAVE IT AT EACH EPOCH, BUT ONLY WHEN THE MODEL WORKS BEST ON THE VALIDATION SET!!\n",
    "    #     if not os.path.exists('./models/' + modelName):\n",
    "    #             os.makedirs('./models/' + modelName)\n",
    "\n",
    "    #         torch.save(net.state_dict(), './models/' + modelName + '/' + str(i) + '_Epoch')\n",
    "\n",
    "    #     np.save(os.path.join(directory, 'Losses.npy'), lossTotalTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f81713-4c18-4dd3-bc72-35dd8f30a339",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      "Total silices is: 1208, labeled slices is: 204\n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: Test_Model\n",
      "Total params: 6,766,344\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PolynomialLR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gheith\\OneDrive - ETS\\0 2023 MTI 865 - Apprentissage profind pour la vision par ordinateur\\CleanedGithub\\MTI865-Competition\\Gheith\\Cross_Teaching_CNN_CNN_plus\\mainSegmentationChallenge.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m runTraining()\n",
      "\u001b[1;32mc:\\Users\\gheith\\OneDrive - ETS\\0 2023 MTI 865 - Apprentissage profind pour la vision par ordinateur\\CleanedGithub\\MTI865-Competition\\Gheith\\Cross_Teaching_CNN_CNN_plus\\mainSegmentationChallenge.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m optimizerK3 \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     \u001b[39mlist\u001b[39m(UEncK3\u001b[39m.\u001b[39mparameters()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(UDecK3\u001b[39m.\u001b[39mparameters()),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     lr\u001b[39m=\u001b[39mbase_lr,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m     weight_decay\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m optimizerK5 \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     \u001b[39mlist\u001b[39m(UEncK3\u001b[39m.\u001b[39mparameters()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(UDecK3\u001b[39m.\u001b[39mparameters()),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m     lr\u001b[39m=\u001b[39mbase_lr,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     weight_decay\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m lr_schedulerK3 \u001b[39m=\u001b[39m PolynomialLR(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     optimizerK3,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     total_iters\u001b[39m=\u001b[39mmax_iterations,  \u001b[39m# The number of steps that the scheduler decays the learning rate.\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     power\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m )  \u001b[39m# The power of the polynomial.\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m lr_schedulerK5 \u001b[39m=\u001b[39m PolynomialLR(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m     optimizerK5,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m     total_iters\u001b[39m=\u001b[39mmax_iterations,  \u001b[39m# The number of steps that the scheduler decays the learning rate.\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m     power\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m )  \u001b[39m# The power of the polynomial.\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gheith/OneDrive%20-%20ETS/0%202023%20MTI%20865%20-%20Apprentissage%20profind%20pour%20la%20vision%20par%20ordinateur/CleanedGithub/MTI865-Competition/Gheith/Cross_Teaching_CNN_CNN_plus/mainSegmentationChallenge.ipynb#W3sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m \u001b[39m### To save statistics ####\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PolynomialLR' is not defined"
     ]
    }
   ],
   "source": [
    "runTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae10184-bacf-4c4d-9767-3272a76a0052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
