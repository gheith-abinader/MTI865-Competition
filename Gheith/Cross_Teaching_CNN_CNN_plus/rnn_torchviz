digraph {
	graph [size="72.75,72.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2154505615312 [label="
 (1, 4, 256, 256)" fillcolor=darkolivegreen1]
	2154504860240 [label=ConvolutionBackward0]
	2154504860096 -> 2154504860240
	2154504860096 [label=LeakyReluBackward0]
	2154504859904 -> 2154504860096
	2154504859904 [label=NativeBatchNormBackward0]
	2154504859808 -> 2154504859904
	2154504859808 [label=ConvolutionBackward0]
	2154504859616 -> 2154504859808
	2154504859616 [label=LeakyReluBackward0]
	2154504859424 -> 2154504859616
	2154504859424 [label=NativeBatchNormBackward0]
	2154504859328 -> 2154504859424
	2154504859328 [label=ConvolutionBackward0]
	2154504858944 -> 2154504859328
	2154504858944 [label=CatBackward0]
	2154504858752 -> 2154504858944
	2154504858752 [label=LeakyReluBackward0]
	2154504858608 -> 2154504858752
	2154504858608 [label=NativeBatchNormBackward0]
	2154504858512 -> 2154504858608
	2154504858512 [label=ConvolutionBackward0]
	2154504858320 -> 2154504858512
	2154504858320 [label=MulBackward0]
	2154504857600 -> 2154504858320
	2154504857600 [label=LeakyReluBackward0]
	2154504857696 -> 2154504857600
	2154504857696 [label=NativeBatchNormBackward0]
	2154504857888 -> 2154504857696
	2154504857888 [label=ConvolutionBackward0]
	2154504858176 -> 2154504857888
	2154504263088 [label="in_conv.conv_conv.0.weight
 (16, 1, 3, 3)" fillcolor=lightblue]
	2154504263088 -> 2154504858176
	2154504858176 [label=AccumulateGrad]
	2154504858128 -> 2154504857888
	2154504263184 [label="in_conv.conv_conv.0.bias
 (16)" fillcolor=lightblue]
	2154504263184 -> 2154504858128
	2154504858128 [label=AccumulateGrad]
	2154504857744 -> 2154504857696
	2154504263280 [label="in_conv.conv_conv.1.weight
 (16)" fillcolor=lightblue]
	2154504263280 -> 2154504857744
	2154504857744 [label=AccumulateGrad]
	2154504857312 -> 2154504857696
	2154504263376 [label="in_conv.conv_conv.1.bias
 (16)" fillcolor=lightblue]
	2154504263376 -> 2154504857312
	2154504857312 [label=AccumulateGrad]
	2154504858368 -> 2154504858512
	2154504263760 [label="in_conv.conv_conv.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2154504263760 -> 2154504858368
	2154504858368 [label=AccumulateGrad]
	2154504858416 -> 2154504858512
	2154504263856 [label="in_conv.conv_conv.4.bias
 (16)" fillcolor=lightblue]
	2154504263856 -> 2154504858416
	2154504858416 [label=AccumulateGrad]
	2154504858560 -> 2154504858608
	2154504263952 [label="in_conv.conv_conv.5.weight
 (16)" fillcolor=lightblue]
	2154504263952 -> 2154504858560
	2154504858560 [label=AccumulateGrad]
	2154504858704 -> 2154504858608
	2154504264048 [label="in_conv.conv_conv.5.bias
 (16)" fillcolor=lightblue]
	2154504264048 -> 2154504858704
	2154504858704 [label=AccumulateGrad]
	2154504858800 -> 2154504858944
	2154504858800 [label=UpsampleBilinear2DBackward0]
	2154504858272 -> 2154504858800
	2154504858272 [label=ConvolutionBackward0]
	2154504857648 -> 2154504858272
	2154504857648 [label=LeakyReluBackward0]
	2154504856976 -> 2154504857648
	2154504856976 [label=NativeBatchNormBackward0]
	2154504857792 -> 2154504856976
	2154504857792 [label=ConvolutionBackward0]
	2154504860960 -> 2154504857792
	2154504860960 [label=LeakyReluBackward0]
	2154504861152 -> 2154504860960
	2154504861152 [label=NativeBatchNormBackward0]
	2154504861248 -> 2154504861152
	2154504861248 [label=ConvolutionBackward0]
	2154504861440 -> 2154504861248
	2154504861440 [label=CatBackward0]
	2154504861632 -> 2154504861440
	2154504861632 [label=LeakyReluBackward0]
	2154504861776 -> 2154504861632
	2154504861776 [label=NativeBatchNormBackward0]
	2154504861872 -> 2154504861776
	2154504861872 [label=ConvolutionBackward0]
	2154504862064 -> 2154504861872
	2154504862064 [label=MulBackward0]
	2154504862256 -> 2154504862064
	2154504862256 [label=LeakyReluBackward0]
	2154504862352 -> 2154504862256
	2154504862352 [label=NativeBatchNormBackward0]
	2154504862448 -> 2154504862352
	2154504862448 [label=ConvolutionBackward0]
	2154504862640 -> 2154504862448
	2154504862640 [label=MaxPool2DWithIndicesBackward0]
	2154504858752 -> 2154504862640
	2154504862592 -> 2154504862448
	2154504264528 [label="down1.maxpool_conv.1.conv_conv.0.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	2154504264528 -> 2154504862592
	2154504862592 [label=AccumulateGrad]
	2154504862544 -> 2154504862448
	2154504264624 [label="down1.maxpool_conv.1.conv_conv.0.bias
 (32)" fillcolor=lightblue]
	2154504264624 -> 2154504862544
	2154504862544 [label=AccumulateGrad]
	2154504862400 -> 2154504862352
	2154504264720 [label="down1.maxpool_conv.1.conv_conv.1.weight
 (32)" fillcolor=lightblue]
	2154504264720 -> 2154504862400
	2154504862400 [label=AccumulateGrad]
	2154504862160 -> 2154504862352
	2154504264816 [label="down1.maxpool_conv.1.conv_conv.1.bias
 (32)" fillcolor=lightblue]
	2154504264816 -> 2154504862160
	2154504862160 [label=AccumulateGrad]
	2154504862016 -> 2154504861872
	2154504265200 [label="down1.maxpool_conv.1.conv_conv.4.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2154504265200 -> 2154504862016
	2154504862016 [label=AccumulateGrad]
	2154504861968 -> 2154504861872
	2154504265296 [label="down1.maxpool_conv.1.conv_conv.4.bias
 (32)" fillcolor=lightblue]
	2154504265296 -> 2154504861968
	2154504861968 [label=AccumulateGrad]
	2154504861824 -> 2154504861776
	2154504265392 [label="down1.maxpool_conv.1.conv_conv.5.weight
 (32)" fillcolor=lightblue]
	2154504265392 -> 2154504861824
	2154504861824 [label=AccumulateGrad]
	2154504861680 -> 2154504861776
	2154504265488 [label="down1.maxpool_conv.1.conv_conv.5.bias
 (32)" fillcolor=lightblue]
	2154504265488 -> 2154504861680
	2154504861680 [label=AccumulateGrad]
	2154504861584 -> 2154504861440
	2154504861584 [label=UpsampleBilinear2DBackward0]
	2154504862112 -> 2154504861584
	2154504862112 [label=ConvolutionBackward0]
	2154504862304 -> 2154504862112
	2154504862304 [label=LeakyReluBackward0]
	2154504862784 -> 2154504862304
	2154504862784 [label=NativeBatchNormBackward0]
	2154504862880 -> 2154504862784
	2154504862880 [label=ConvolutionBackward0]
	2154504863072 -> 2154504862880
	2154504863072 [label=LeakyReluBackward0]
	2154504863264 -> 2154504863072
	2154504863264 [label=NativeBatchNormBackward0]
	2154504863360 -> 2154504863264
	2154504863360 [label=ConvolutionBackward0]
	2154504863552 -> 2154504863360
	2154504863552 [label=CatBackward0]
	2154504863696 -> 2154504863552
	2154504863696 [label=LeakyReluBackward0]
	2154505863376 -> 2154504863696
	2154505863376 [label=NativeBatchNormBackward0]
	2154505863472 -> 2154505863376
	2154505863472 [label=ConvolutionBackward0]
	2154505863664 -> 2154505863472
	2154505863664 [label=MulBackward0]
	2154505863856 -> 2154505863664
	2154505863856 [label=LeakyReluBackward0]
	2154505863952 -> 2154505863856
	2154505863952 [label=NativeBatchNormBackward0]
	2154505864048 -> 2154505863952
	2154505864048 [label=ConvolutionBackward0]
	2154505864240 -> 2154505864048
	2154505864240 [label=MaxPool2DWithIndicesBackward0]
	2154504861632 -> 2154505864240
	2154505864192 -> 2154505864048
	2154504265872 [label="down2.maxpool_conv.1.conv_conv.0.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	2154504265872 -> 2154505864192
	2154505864192 [label=AccumulateGrad]
	2154505864144 -> 2154505864048
	2154504265968 [label="down2.maxpool_conv.1.conv_conv.0.bias
 (64)" fillcolor=lightblue]
	2154504265968 -> 2154505864144
	2154505864144 [label=AccumulateGrad]
	2154505864000 -> 2154505863952
	2154504266064 [label="down2.maxpool_conv.1.conv_conv.1.weight
 (64)" fillcolor=lightblue]
	2154504266064 -> 2154505864000
	2154505864000 [label=AccumulateGrad]
	2154505863760 -> 2154505863952
	2154504266160 [label="down2.maxpool_conv.1.conv_conv.1.bias
 (64)" fillcolor=lightblue]
	2154504266160 -> 2154505863760
	2154505863760 [label=AccumulateGrad]
	2154505863616 -> 2154505863472
	2154504266544 [label="down2.maxpool_conv.1.conv_conv.4.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2154504266544 -> 2154505863616
	2154505863616 [label=AccumulateGrad]
	2154505863568 -> 2154505863472
	2154504266640 [label="down2.maxpool_conv.1.conv_conv.4.bias
 (64)" fillcolor=lightblue]
	2154504266640 -> 2154505863568
	2154505863568 [label=AccumulateGrad]
	2154505863424 -> 2154505863376
	2154504266736 [label="down2.maxpool_conv.1.conv_conv.5.weight
 (64)" fillcolor=lightblue]
	2154504266736 -> 2154505863424
	2154505863424 [label=AccumulateGrad]
	2154505863280 -> 2154505863376
	2154504266832 [label="down2.maxpool_conv.1.conv_conv.5.bias
 (64)" fillcolor=lightblue]
	2154504266832 -> 2154505863280
	2154505863280 [label=AccumulateGrad]
	2154504863648 -> 2154504863552
	2154504863648 [label=UpsampleBilinear2DBackward0]
	2154505863712 -> 2154504863648
	2154505863712 [label=ConvolutionBackward0]
	2154505863904 -> 2154505863712
	2154505863904 [label=LeakyReluBackward0]
	2154505864384 -> 2154505863904
	2154505864384 [label=NativeBatchNormBackward0]
	2154505864480 -> 2154505864384
	2154505864480 [label=ConvolutionBackward0]
	2154505864672 -> 2154505864480
	2154505864672 [label=LeakyReluBackward0]
	2154505864864 -> 2154505864672
	2154505864864 [label=NativeBatchNormBackward0]
	2154505864960 -> 2154505864864
	2154505864960 [label=ConvolutionBackward0]
	2154505865152 -> 2154505864960
	2154505865152 [label=CatBackward0]
	2154505865344 -> 2154505865152
	2154505865344 [label=LeakyReluBackward0]
	2154505865488 -> 2154505865344
	2154505865488 [label=NativeBatchNormBackward0]
	2154505865584 -> 2154505865488
	2154505865584 [label=ConvolutionBackward0]
	2154505865776 -> 2154505865584
	2154505865776 [label=MulBackward0]
	2154505865968 -> 2154505865776
	2154505865968 [label=LeakyReluBackward0]
	2154505866064 -> 2154505865968
	2154505866064 [label=NativeBatchNormBackward0]
	2154505866112 -> 2154505866064
	2154505866112 [label=ConvolutionBackward0]
	2154505866400 -> 2154505866112
	2154505866400 [label=MaxPool2DWithIndicesBackward0]
	2154504863696 -> 2154505866400
	2154505866352 -> 2154505866112
	2154504267216 [label="down3.maxpool_conv.1.conv_conv.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2154504267216 -> 2154505866352
	2154505866352 [label=AccumulateGrad]
	2154505866304 -> 2154505866112
	2154504267312 [label="down3.maxpool_conv.1.conv_conv.0.bias
 (128)" fillcolor=lightblue]
	2154504267312 -> 2154505866304
	2154505866304 [label=AccumulateGrad]
	2154505865872 -> 2154505866064
	2154504267408 [label="down3.maxpool_conv.1.conv_conv.1.weight
 (128)" fillcolor=lightblue]
	2154504267408 -> 2154505865872
	2154505865872 [label=AccumulateGrad]
	2154505866208 -> 2154505866064
	2154504267504 [label="down3.maxpool_conv.1.conv_conv.1.bias
 (128)" fillcolor=lightblue]
	2154504267504 -> 2154505866208
	2154505866208 [label=AccumulateGrad]
	2154505865728 -> 2154505865584
	2154504267888 [label="down3.maxpool_conv.1.conv_conv.4.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2154504267888 -> 2154505865728
	2154505865728 [label=AccumulateGrad]
	2154505865680 -> 2154505865584
	2154504267984 [label="down3.maxpool_conv.1.conv_conv.4.bias
 (128)" fillcolor=lightblue]
	2154504267984 -> 2154505865680
	2154505865680 [label=AccumulateGrad]
	2154505865536 -> 2154505865488
	2154504268080 [label="down3.maxpool_conv.1.conv_conv.5.weight
 (128)" fillcolor=lightblue]
	2154504268080 -> 2154505865536
	2154505865536 [label=AccumulateGrad]
	2154505865392 -> 2154505865488
	2154504268176 [label="down3.maxpool_conv.1.conv_conv.5.bias
 (128)" fillcolor=lightblue]
	2154504268176 -> 2154505865392
	2154505865392 [label=AccumulateGrad]
	2154505865296 -> 2154505865152
	2154505865296 [label=UpsampleBilinear2DBackward0]
	2154505865824 -> 2154505865296
	2154505865824 [label=ConvolutionBackward0]
	2154505866016 -> 2154505865824
	2154505866016 [label=LeakyReluBackward0]
	2154505866640 -> 2154505866016
	2154505866640 [label=NativeBatchNormBackward0]
	2154505866736 -> 2154505866640
	2154505866736 [label=ConvolutionBackward0]
	2154505866928 -> 2154505866736
	2154505866928 [label=MulBackward0]
	2154505867120 -> 2154505866928
	2154505867120 [label=LeakyReluBackward0]
	2154505867216 -> 2154505867120
	2154505867216 [label=NativeBatchNormBackward0]
	2154505867312 -> 2154505867216
	2154505867312 [label=ConvolutionBackward0]
	2154505867504 -> 2154505867312
	2154505867504 [label=MaxPool2DWithIndicesBackward0]
	2154505865344 -> 2154505867504
	2154505867456 -> 2154505867312
	2154504268560 [label="down4.maxpool_conv.1.conv_conv.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2154504268560 -> 2154505867456
	2154505867456 [label=AccumulateGrad]
	2154505867408 -> 2154505867312
	2154504268656 [label="down4.maxpool_conv.1.conv_conv.0.bias
 (256)" fillcolor=lightblue]
	2154504268656 -> 2154505867408
	2154505867408 [label=AccumulateGrad]
	2154505867264 -> 2154505867216
	2154504268752 [label="down4.maxpool_conv.1.conv_conv.1.weight
 (256)" fillcolor=lightblue]
	2154504268752 -> 2154505867264
	2154505867264 [label=AccumulateGrad]
	2154505867024 -> 2154505867216
	2154504268848 [label="down4.maxpool_conv.1.conv_conv.1.bias
 (256)" fillcolor=lightblue]
	2154504268848 -> 2154505867024
	2154505867024 [label=AccumulateGrad]
	2154505866880 -> 2154505866736
	2154504269232 [label="down4.maxpool_conv.1.conv_conv.4.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2154504269232 -> 2154505866880
	2154505866880 [label=AccumulateGrad]
	2154505866832 -> 2154505866736
	2154504269328 [label="down4.maxpool_conv.1.conv_conv.4.bias
 (256)" fillcolor=lightblue]
	2154504269328 -> 2154505866832
	2154505866832 [label=AccumulateGrad]
	2154505866688 -> 2154505866640
	2154504269424 [label="down4.maxpool_conv.1.conv_conv.5.weight
 (256)" fillcolor=lightblue]
	2154504269424 -> 2154505866688
	2154505866688 [label=AccumulateGrad]
	2154505866448 -> 2154505866640
	2154504269520 [label="down4.maxpool_conv.1.conv_conv.5.bias
 (256)" fillcolor=lightblue]
	2154504269520 -> 2154505866448
	2154505866448 [label=AccumulateGrad]
	2154505865920 -> 2154505865824
	2154504269904 [label="up1.conv1x1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2154504269904 -> 2154505865920
	2154505865920 [label=AccumulateGrad]
	2154505865440 -> 2154505865824
	2154504270000 [label="up1.conv1x1.bias
 (128)" fillcolor=lightblue]
	2154504270000 -> 2154505865440
	2154505865440 [label=AccumulateGrad]
	2154505865104 -> 2154505864960
	2154504270096 [label="up1.conv.conv_conv.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	2154504270096 -> 2154505865104
	2154505865104 [label=AccumulateGrad]
	2154505865056 -> 2154505864960
	2154504270192 [label="up1.conv.conv_conv.0.bias
 (128)" fillcolor=lightblue]
	2154504270192 -> 2154505865056
	2154505865056 [label=AccumulateGrad]
	2154505864912 -> 2154505864864
	2154504270288 [label="up1.conv.conv_conv.1.weight
 (128)" fillcolor=lightblue]
	2154504270288 -> 2154505864912
	2154505864912 [label=AccumulateGrad]
	2154505864768 -> 2154505864864
	2154504270384 [label="up1.conv.conv_conv.1.bias
 (128)" fillcolor=lightblue]
	2154504270384 -> 2154505864768
	2154505864768 [label=AccumulateGrad]
	2154505864624 -> 2154505864480
	2154504270768 [label="up1.conv.conv_conv.4.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2154504270768 -> 2154505864624
	2154505864624 [label=AccumulateGrad]
	2154505864576 -> 2154505864480
	2154504270864 [label="up1.conv.conv_conv.4.bias
 (128)" fillcolor=lightblue]
	2154504270864 -> 2154505864576
	2154505864576 [label=AccumulateGrad]
	2154505864336 -> 2154505864384
	2154504270960 [label="up1.conv.conv_conv.5.weight
 (128)" fillcolor=lightblue]
	2154504270960 -> 2154505864336
	2154505864336 [label=AccumulateGrad]
	2154505864288 -> 2154505864384
	2154504271056 [label="up1.conv.conv_conv.5.bias
 (128)" fillcolor=lightblue]
	2154504271056 -> 2154505864288
	2154505864288 [label=AccumulateGrad]
	2154505863808 -> 2154505863712
	2154504271440 [label="up2.conv1x1.weight
 (64, 128, 1, 1)" fillcolor=lightblue]
	2154504271440 -> 2154505863808
	2154505863808 [label=AccumulateGrad]
	2154505863328 -> 2154505863712
	2154504271536 [label="up2.conv1x1.bias
 (64)" fillcolor=lightblue]
	2154504271536 -> 2154505863328
	2154505863328 [label=AccumulateGrad]
	2154504863504 -> 2154504863360
	2154504271632 [label="up2.conv.conv_conv.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	2154504271632 -> 2154504863504
	2154504863504 [label=AccumulateGrad]
	2154504863456 -> 2154504863360
	2154504271728 [label="up2.conv.conv_conv.0.bias
 (64)" fillcolor=lightblue]
	2154504271728 -> 2154504863456
	2154504863456 [label=AccumulateGrad]
	2154504863312 -> 2154504863264
	2154504271824 [label="up2.conv.conv_conv.1.weight
 (64)" fillcolor=lightblue]
	2154504271824 -> 2154504863312
	2154504863312 [label=AccumulateGrad]
	2154504863168 -> 2154504863264
	2154504271920 [label="up2.conv.conv_conv.1.bias
 (64)" fillcolor=lightblue]
	2154504271920 -> 2154504863168
	2154504863168 [label=AccumulateGrad]
	2154504863024 -> 2154504862880
	2154504272304 [label="up2.conv.conv_conv.4.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2154504272304 -> 2154504863024
	2154504863024 [label=AccumulateGrad]
	2154504862976 -> 2154504862880
	2154504272400 [label="up2.conv.conv_conv.4.bias
 (64)" fillcolor=lightblue]
	2154504272400 -> 2154504862976
	2154504862976 [label=AccumulateGrad]
	2154504862736 -> 2154504862784
	2154504272496 [label="up2.conv.conv_conv.5.weight
 (64)" fillcolor=lightblue]
	2154504272496 -> 2154504862736
	2154504862736 [label=AccumulateGrad]
	2154504862688 -> 2154504862784
	2154504272592 [label="up2.conv.conv_conv.5.bias
 (64)" fillcolor=lightblue]
	2154504272592 -> 2154504862688
	2154504862688 [label=AccumulateGrad]
	2154504862208 -> 2154504862112
	2154504272976 [label="up3.conv1x1.weight
 (32, 64, 1, 1)" fillcolor=lightblue]
	2154504272976 -> 2154504862208
	2154504862208 [label=AccumulateGrad]
	2154504861728 -> 2154504862112
	2154504273072 [label="up3.conv1x1.bias
 (32)" fillcolor=lightblue]
	2154504273072 -> 2154504861728
	2154504861728 [label=AccumulateGrad]
	2154504861392 -> 2154504861248
	2154504273168 [label="up3.conv.conv_conv.0.weight
 (32, 64, 3, 3)" fillcolor=lightblue]
	2154504273168 -> 2154504861392
	2154504861392 [label=AccumulateGrad]
	2154504861344 -> 2154504861248
	2154504273264 [label="up3.conv.conv_conv.0.bias
 (32)" fillcolor=lightblue]
	2154504273264 -> 2154504861344
	2154504861344 [label=AccumulateGrad]
	2154504861200 -> 2154504861152
	2154504273360 [label="up3.conv.conv_conv.1.weight
 (32)" fillcolor=lightblue]
	2154504273360 -> 2154504861200
	2154504861200 [label=AccumulateGrad]
	2154504861056 -> 2154504861152
	2154504273456 [label="up3.conv.conv_conv.1.bias
 (32)" fillcolor=lightblue]
	2154504273456 -> 2154504861056
	2154504861056 [label=AccumulateGrad]
	2154504860912 -> 2154504857792
	2154504273840 [label="up3.conv.conv_conv.4.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2154504273840 -> 2154504860912
	2154504860912 [label=AccumulateGrad]
	2154504860864 -> 2154504857792
	2154505601104 [label="up3.conv.conv_conv.4.bias
 (32)" fillcolor=lightblue]
	2154505601104 -> 2154504860864
	2154504860864 [label=AccumulateGrad]
	2154504857840 -> 2154504856976
	2154505601200 [label="up3.conv.conv_conv.5.weight
 (32)" fillcolor=lightblue]
	2154505601200 -> 2154504857840
	2154504857840 [label=AccumulateGrad]
	2154504858080 -> 2154504856976
	2154505601296 [label="up3.conv.conv_conv.5.bias
 (32)" fillcolor=lightblue]
	2154505601296 -> 2154504858080
	2154504858080 [label=AccumulateGrad]
	2154504857360 -> 2154504858272
	2154505601680 [label="up4.conv1x1.weight
 (16, 32, 1, 1)" fillcolor=lightblue]
	2154505601680 -> 2154504857360
	2154504857360 [label=AccumulateGrad]
	2154504858656 -> 2154504858272
	2154505601776 [label="up4.conv1x1.bias
 (16)" fillcolor=lightblue]
	2154505601776 -> 2154504858656
	2154504858656 [label=AccumulateGrad]
	2154504858992 -> 2154504859328
	2154505601872 [label="up4.conv.conv_conv.0.weight
 (16, 32, 3, 3)" fillcolor=lightblue]
	2154505601872 -> 2154504858992
	2154504858992 [label=AccumulateGrad]
	2154504859232 -> 2154504859328
	2154505601968 [label="up4.conv.conv_conv.0.bias
 (16)" fillcolor=lightblue]
	2154505601968 -> 2154504859232
	2154504859232 [label=AccumulateGrad]
	2154504859376 -> 2154504859424
	2154505602064 [label="up4.conv.conv_conv.1.weight
 (16)" fillcolor=lightblue]
	2154505602064 -> 2154504859376
	2154504859376 [label=AccumulateGrad]
	2154504859520 -> 2154504859424
	2154505602160 [label="up4.conv.conv_conv.1.bias
 (16)" fillcolor=lightblue]
	2154505602160 -> 2154504859520
	2154504859520 [label=AccumulateGrad]
	2154504859664 -> 2154504859808
	2154505602544 [label="up4.conv.conv_conv.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	2154505602544 -> 2154504859664
	2154504859664 [label=AccumulateGrad]
	2154504859712 -> 2154504859808
	2154505602640 [label="up4.conv.conv_conv.4.bias
 (16)" fillcolor=lightblue]
	2154505602640 -> 2154504859712
	2154504859712 [label=AccumulateGrad]
	2154504859856 -> 2154504859904
	2154505602736 [label="up4.conv.conv_conv.5.weight
 (16)" fillcolor=lightblue]
	2154505602736 -> 2154504859856
	2154504859856 [label=AccumulateGrad]
	2154504859952 -> 2154504859904
	2154505602832 [label="up4.conv.conv_conv.5.bias
 (16)" fillcolor=lightblue]
	2154505602832 -> 2154504859952
	2154504859952 [label=AccumulateGrad]
	2154504860048 -> 2154504860240
	2154505603216 [label="out_conv.weight
 (4, 16, 3, 3)" fillcolor=lightblue]
	2154505603216 -> 2154504860048
	2154504860048 [label=AccumulateGrad]
	2154504860000 -> 2154504860240
	2154505603312 [label="out_conv.bias
 (4)" fillcolor=lightblue]
	2154505603312 -> 2154504860000
	2154504860000 [label=AccumulateGrad]
	2154504860240 -> 2154505615312
}
