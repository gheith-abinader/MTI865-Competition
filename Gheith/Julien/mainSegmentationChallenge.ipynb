{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HLoss, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = F.softmax(x, dim=1) * F.log_softmax(x, dim=1)\n",
    "        b = -1.0 * b.mean()\n",
    "        # b = -1.0 * b.sum() # If using this one, the value on the final loss for eloss is 0.0000001\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "220c7dcc-8438-454d-97b1-8e989a7b8f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runTraining():\n",
    "    print('-' * 40)\n",
    "    print('~~~~~~~~  Starting the training... ~~~~~~')\n",
    "    print('-' * 40)\n",
    "\n",
    "    ## DEFINE HYPERPARAMETERS (batch_size > 1)\n",
    "    batch_size = 32\n",
    "    batch_size_val = 16\n",
    "    lr =  0.001   # Learning Rate\n",
    "    epoch = 100 # Number of epochs\n",
    "\n",
    "    loss_weight = [0.7, 0.3] # Weight for the loss function (CE, Dice)\n",
    "    CE_weights = [0.05, 0.40, 0.30, 0.25] # Weight for the Cross Entropy loss function\n",
    "    \n",
    "    root_dir = './Data/'\n",
    "    print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                      root_dir,\n",
    "                                                      transform=transform,\n",
    "                                                      mask_transform=mask_transform,\n",
    "                                                      augment=True,\n",
    "                                                      equalize=False)\n",
    "\n",
    "    train_loader_full = DataLoader(train_set_full,\n",
    "                              batch_size=batch_size,\n",
    "                              worker_init_fn=np.random.seed(0),\n",
    "                              num_workers=0,\n",
    "                              shuffle=True)\n",
    "\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    equalize=False)\n",
    "\n",
    "    val_loader = DataLoader(val_set,\n",
    "                            batch_size=batch_size_val,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "\n",
    "\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    num_classes = 4 # NUMBER OF CLASSES\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = 'Test_Model'\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    # net = UNet(num_classes)\n",
    "    net = smp.Unet('resnet34', encoder_weights='imagenet', in_channels=1, classes=num_classes)\n",
    "\n",
    "    print(\"Total params: {0:,}\".format(sum(p.numel() for p in net.parameters() if p.requires_grad)))\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax()\n",
    "    # CE_loss = torch.nn.CrossEntropyLoss(weight=torch.Tensor([0.05, 0.35, 0.30, 0.30]))\n",
    "    # DSC_loss_weight = 0.4\n",
    "    # Dice_loss = smp.losses.DiceLoss(mode='multiclass', classes=[1, 2, 3])\n",
    "    CE_loss = torch.nn.CrossEntropyLoss(weight=torch.Tensor(CE_weights))\n",
    "    Dice_loss = smp.losses.DiceLoss(mode='multiclass', ignore_index=0)\n",
    "\n",
    "    ## PUT EVERYTHING IN GPU RESOURCES    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        softMax.cuda()\n",
    "        CE_loss.cuda()\n",
    "        Dice_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=0.0001)\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    lossTotalValidation = []\n",
    "    Best_loss_val = 1000\n",
    "    BestEpoch = 0\n",
    "    no_improvement_counter = 0\n",
    "        \n",
    "    directory = 'Results/Statistics/' + modelName\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory)==False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "    \n",
    "    ## FOR EACH EPOCH\n",
    "    for i in range(epoch):\n",
    "        net.train()\n",
    "        lossEpochTrain = []\n",
    "        DSCEpoch = []\n",
    "        DSCEpoch_w = []\n",
    "        num_batches = len(train_loader_full)\n",
    "        \n",
    "        ## FOR EACH BATCH\n",
    "        for j, data in enumerate(train_loader_full):\n",
    "            ### Set to zero all the gradients\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, img_names = data\n",
    "\n",
    "            ### From numpy to torch variables\n",
    "            labels = to_var(labels)\n",
    "            images = to_var(images)\n",
    "\n",
    "            ################### Train ###################\n",
    "            #-- The CNN makes its predictions (forward pass)\n",
    "            net_predictions = net(images)\n",
    "\n",
    "            #-- Compute the losses --#\n",
    "            # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            \n",
    "            # COMPUTE THE LOSS\n",
    "            CE_loss_value = CE_loss(net_predictions, segmentation_classes)\n",
    "            \n",
    "            predsoft = softMax(net_predictions)\n",
    "            pred = predsoft.argmax(dim=1)\n",
    "\n",
    "            #Show live view of model segmentation\n",
    "            if not os.path.exists('Results/Segmentation/'):\n",
    "                os.makedirs('Results/Segmentation/')\n",
    "            torchvision.utils.save_image(torch.cat([pred.view(labels.shape[0], 1, 256, 256).data / 3.0]), 'Results/Segmentation/liveview.png'.format(i))\n",
    "\n",
    "            # Dice_loss_value = computeDSC(pred.unsqueeze(1), segmentation_classes.unsqueeze(1))\n",
    "            Dice_loss_value = Dice_loss(predsoft, segmentation_classes)\n",
    "\n",
    "            lossTotal = loss_weight[0]*CE_loss_value + loss_weight[1]*(Dice_loss_value)\n",
    "\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            lossTotal.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING \n",
    "            lossEpochTrain.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches,\n",
    "                             prefix=\"[Training] Epoch: {} \".format(i),\n",
    "                             length=15,\n",
    "                             suffix=\" Loss: {:.4f}, CE: {:.4f}, Dice: {:.8f}\".format(lossTotal, CE_loss_value, Dice_loss_value))\n",
    "\n",
    "        lossEpochTrain = np.asarray(lossEpochTrain)\n",
    "        lossEpochTrain = lossEpochTrain.mean()\n",
    "\n",
    "        lossTotalTraining.append(lossEpochTrain)\n",
    "\n",
    "        printProgressBar(num_batches, num_batches,\n",
    "                             done=\"[Training] Epoch: {}, LossG: {:.4f}\".format(i,lossEpochTrain))\n",
    "\n",
    "        # Validation\n",
    "        net.eval()\n",
    "        lossEpochVal = []\n",
    "        num_batches = len(val_loader)\n",
    "        \n",
    "        for j,data in enumerate(val_loader):\n",
    "            images, labels, img_names = data\n",
    "            labels = to_var(labels)\n",
    "            images = to_var(images)\n",
    "\n",
    "            net_predictions = net(images)\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            CE_loss_value = CE_loss(net_predictions, segmentation_classes)\n",
    "            \n",
    "            predsoft = softMax(net_predictions)\n",
    "            pred = predsoft.argmax(dim=1)\n",
    "\n",
    "            #Show live view of model segmentation\n",
    "            if not os.path.exists('Results/Segmentation/'):\n",
    "                os.makedirs('Results/Segmentation/')\n",
    "            torchvision.utils.save_image(torch.cat([pred.view(labels.shape[0], 1, 256, 256).data / 3.0]), 'Results/Segmentation/liveview.png'.format(i))\n",
    "            \n",
    "            # Dice_loss_value = computeDSC(pred.unsqueeze(1), segmentation_classes.unsqueeze(1))\n",
    "            Dice_loss_value = Dice_loss(predsoft, segmentation_classes)\n",
    "\n",
    "            lossTotal = loss_weight[0]*CE_loss_value + loss_weight[1]*(Dice_loss_value)\n",
    "\n",
    "            lossEpochVal.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches,\n",
    "                             prefix=\"[Validation] Epoch: {} \".format(i),\n",
    "                             length=15,\n",
    "                             suffix=\" Loss: {:.4f}, CE: {:.4f}, Dice: {:.8f}\".format(lossTotal, CE_loss_value, Dice_loss_value))\n",
    "            \n",
    "        lossEpochVal = np.asarray(lossEpochVal)\n",
    "        lossEpochVal = lossEpochVal.mean()\n",
    "\n",
    "        lossTotalValidation.append(lossEpochVal)\n",
    "\n",
    "        printProgressBar(num_batches, num_batches,\n",
    "                             done=\"[Validation] Epoch: {}, LossG: {:.4f}\".format(i,lossEpochVal))\n",
    "\n",
    "        # Save the model if it is the best so far\n",
    "\n",
    "        if lossEpochVal < Best_loss_val:\n",
    "            Best_loss_val = lossEpochVal\n",
    "            BestEpoch = i\n",
    "            no_improvement_counter = 0\n",
    "\n",
    "            if not os.path.exists('./models/' + modelName):\n",
    "                os.makedirs('./models/' + modelName)\n",
    "            torch.save(net.state_dict(), './models/' + modelName + '/' + str(i) + '_Epoch')\n",
    "            print('Best model saved at epoch {}'.format(i))\n",
    "        else:\n",
    "            no_improvement_counter = no_improvement_counter + 1\n",
    "            print('No improvement in last epoch. Counter: {}'.format(no_improvement_counter))\n",
    "            if no_improvement_counter % 3 == 0 and no_improvement_counter != 0:\n",
    "                print('No improvement in last 3 epochs. Lowering learning rate.')\n",
    "                lr = lr/10\n",
    "                optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "            if i - BestEpoch > 7:\n",
    "                print('No improvement in last 7 epochs. Stopping training.')\n",
    "                break\n",
    "\n",
    "    np.save(os.path.join(directory, 'Losses.npy'), lossTotalTraining)\n",
    "    np.save(os.path.join(directory, 'Losses_val.npy'), lossTotalValidation)\n",
    "\n",
    "    print('Training finished. Best model saved at epoch {}'.format(BestEpoch))\n",
    "\n",
    "    graphLosses(lossTotalTraining, lossTotalValidation, modelName, directory)\n",
    "\n",
    "    return BestEpoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation and segmentation\n",
    "def runEvaluation(BestEpoch):\n",
    "\n",
    "    #Load the best model\n",
    "    modelName = 'Test_Model'\n",
    "    # net = UNet(4)\n",
    "    net = smp.Unet('resnet34', encoder_weights='imagenet', in_channels=1, classes=4)\n",
    "    net.load_state_dict(torch.load('./models/' + modelName + '/' + str(BestEpoch) + '_Epoch'))\n",
    "    # net.load_state_dict(torch.load('./Saved_Models/Model_loss_0_0190'))\n",
    "\n",
    "    #Load the val set\n",
    "    batch_size_val = 8\n",
    "    root_dir = './Data/'\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    equalize=False)\n",
    "    val_loader = DataLoader(val_set,\n",
    "                            batch_size=batch_size_val,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "    \n",
    "\n",
    "    loss, tp, fp, fn, tn = inference(net, val_loader, modelName, BestEpoch)\n",
    "\n",
    "    def metric_print(tp, fp, fn, tn):\n",
    "        f1_score = tp/(tp + 0.5*(fp + fn))\n",
    "        precision = tp/(tp + fp)\n",
    "        recall = tp/(tp + fn)\n",
    "        accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "        ballanced_accuracy = 0.5*(tp/(tp + fn) + tn/(tn + fp))\n",
    "        jaccard = tp/(tp + fp + fn)\n",
    "        sensitivity = tp/(tp + fn)\n",
    "        specificity = tn/(tn + fp)\n",
    "        print('     ---------- Data ----------')\n",
    "        print('                TP: {}'.format(tp))\n",
    "        print('                FP: {}'.format(fp))\n",
    "        print('                FN: {}'.format(fn))\n",
    "        print('                TN: {}'.format(tn))\n",
    "        print('     ---------- Metrics ----------')\n",
    "        print('          F1 score: {}'.format(f1_score))\n",
    "        print('         Precision: {}'.format(precision))\n",
    "        print('            Recall: {}'.format(recall))\n",
    "        print('          Accuracy: {}'.format(accuracy))\n",
    "        print('Ballanced accuracy: {}'.format(ballanced_accuracy))\n",
    "        print('           Jaccard: {}'.format(jaccard))\n",
    "        print('       Sensitivity: {}'.format(sensitivity))\n",
    "        print('       Specificity: {}'.format(specificity))\n",
    "        print('')\n",
    "\n",
    "    print('     ---------- Loss ----------')\n",
    "    print('           CE Loss: {}'.format(loss))\n",
    "    print('')\n",
    "    print('     ---------- Class 1 (BG) ----------')\n",
    "    metric_print(tn[0], fp[0], fn[0], tp[0])\n",
    "    print('     ---------- Class 2  ----------')\n",
    "    metric_print(tn[1], fp[1], fn[1], tp[1])\n",
    "    print('     ---------- Class 3  ----------')\n",
    "    metric_print(tn[2], fp[2], fn[2], tp[2])\n",
    "    print('     ---------- Class 4  ----------')\n",
    "    metric_print(tn[3], fp[3], fn[3], tp[3])\n",
    "    print('     ---------- Total  ----------')\n",
    "    metric_print(np.sum(tp), np.sum(fp), np.sum(fn), np.sum(tn))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTesting(modelName='Test_Model', BestEpoch=0):\n",
    "    print('-' * 40)\n",
    "    print('~~~~~~~~  Starting the testing... ~~~~~~')\n",
    "    print('-' * 40)\n",
    "\n",
    "    batch_size_val = 1\n",
    "    root_dir = './Data/'\n",
    "\n",
    "    # https://sparrow.dev/pytorch-normalize/\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        # transforms.Normalize((0.5), (0.20))\n",
    "    ])\n",
    "\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    test_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                     root_dir,\n",
    "                                                     transform=transform,\n",
    "                                                     mask_transform=mask_transform,\n",
    "                                                     equalize=False)\n",
    "\n",
    "    test_loader = DataLoader(test_set,\n",
    "                             batch_size=batch_size_val,\n",
    "                             num_workers=5,\n",
    "                             shuffle=False)\n",
    "\n",
    "    # Initialize\n",
    "    num_classes = 4\n",
    "\n",
    "    # Create and load model\n",
    "    # net = UNet(num_classes)\n",
    "    net = smp.Unet('resnet34', encoder_weights='imagenet', in_channels=1, classes=4)\n",
    "\n",
    "    # Load\n",
    "    # net.load_state_dict(torch.load('./models/'+modelName))\n",
    "    net.load_state_dict(torch.load('./models/' + modelName + '/' + str(BestEpoch) + '_Epoch'))\n",
    "    # net.load_state_dict(torch.load('./Saved_Models/Model_loss_0_0190'))\n",
    "    net.eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the testing ~~~~~~~~~~\")\n",
    "    [DSC1, DSC1s, DSC2, DSC2s, DSC3, DSC3s, HD1, HD1s, HD2, HD2s, HD3, HD3s, ASD1,\n",
    "        ASD1s, ASD2, ASD2s, ASD3, ASD3s] = inferenceTest(net, test_loader, modelName)\n",
    "\n",
    "    print(\"###                                                       ###\")\n",
    "    print(\"###         TEST RESULTS                                  ###\")\n",
    "    print(\"###  Dice : c1: {:.4f} ({:.4f}) c2: {:.4f} ({:.4f}) c3: {:.4f} ({:.4f}) Mean: {:.4f} ({:.4f}) ###\".format(DSC1,\n",
    "                                                                                                                     DSC1s,\n",
    "                                                                                                                     DSC2,\n",
    "                                                                                                                     DSC2s,\n",
    "                                                                                                                     DSC3,\n",
    "                                                                                                                     DSC3s,\n",
    "                                                                                                                     (DSC1+DSC2+DSC3)/3,\n",
    "                                                                                                                     (DSC1s+DSC2s+DSC3s)/3))\n",
    "    print(\"###  HD   : c1: {:.4f} ({:.4f}) c2: {:.4f} ({:.4f}) c3: {:.4f} ({:.4f}) Mean: {:.4f} ({:.4f}) ###\".format(HD1,\n",
    "                                                                                                                     HD1s,\n",
    "                                                                                                                     HD2,\n",
    "                                                                                                                     HD2s,\n",
    "                                                                                                                     HD3,\n",
    "                                                                                                                     HD3s,\n",
    "                                                                                                                     (HD1 + HD2 + HD3) / 3,\n",
    "                                                                                                                     (HD1s + HD2s + HD3s) / 3))\n",
    "    print(\"###  ASD  : c1: {:.4f} ({:.4f}) c2: {:.4f} ({:.4f}) c3: {:.4f} ({:.4f}) Mean: {:.4f} ({:.4f}) ###\".format(ASD1,\n",
    "                                                                                                                     ASD1s,\n",
    "                                                                                                                     ASD2,\n",
    "                                                                                                                     ASD2s,\n",
    "                                                                                                                     ASD3,\n",
    "                                                                                                                     ASD3s,\n",
    "                                                                                                                     (ASD1 + ASD2 + ASD3) / 3,\n",
    "                                                                                                                     (ASD1s + ASD2s + ASD3s) / 3))\n",
    "    print(\"###                                                       ###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67f81713-4c18-4dd3-bc72-35dd8f30a339",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      " Dataset: ./Data/ \n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: Test_Model\n",
      "Total params: 24,430,532\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "[Training] Epoch: 0 [DONE]                                                             \n",
      "[Training] Epoch: 0, LossG: 1.2238                                                                           \n",
      "[Validation] Epoch: 0 [DONE]                                                             \n",
      "[Validation] Epoch: 0, LossG: 1.4389                                                                         \n",
      "Best model saved at epoch 0\n",
      "[Training] Epoch: 1 [DONE]                                                             \n",
      "[Training] Epoch: 1, LossG: 0.8646                                                                           \n",
      "[Validation] Epoch: 1 [DONE]                                                             \n",
      "[Validation] Epoch: 1, LossG: 0.9477                                                                         \n",
      "Best model saved at epoch 1\n",
      "[Training] Epoch: 2 [DONE]                                                             \n",
      "[Training] Epoch: 2, LossG: 0.6737                                                                           \n",
      "[Validation] Epoch: 2 [DONE]                                                             \n",
      "[Validation] Epoch: 2, LossG: 0.7813                                                                         \n",
      "Best model saved at epoch 2\n",
      "[Training] Epoch: 3 [DONE]                                                             \n",
      "[Training] Epoch: 3, LossG: 0.5710                                                                           \n",
      "[Validation] Epoch: 3 [DONE]                                                             \n",
      "[Validation] Epoch: 3, LossG: 0.6465                                                                         \n",
      "Best model saved at epoch 3\n",
      "[Training] Epoch: 4 [DONE]                                                             \n",
      "[Training] Epoch: 4, LossG: 0.5117                                                                           \n",
      "[Validation] Epoch: 4 [DONE]                                                             \n",
      "[Validation] Epoch: 4, LossG: 0.5315                                                                         \n",
      "Best model saved at epoch 4\n",
      "[Training] Epoch: 5 [DONE]                                                             \n",
      "[Training] Epoch: 5, LossG: 0.4742                                                                           \n",
      "[Validation] Epoch: 5 [DONE]                                                             \n",
      "[Validation] Epoch: 5, LossG: 0.5109                                                                         \n",
      "Best model saved at epoch 5\n",
      "[Training] Epoch: 6 [DONE]                                                             \n",
      "[Training] Epoch: 6, LossG: 0.4412                                                                           \n",
      "[Validation] Epoch: 6 [DONE]                                                             \n",
      "[Validation] Epoch: 6, LossG: 0.4595                                                                         \n",
      "Best model saved at epoch 6\n",
      "[Training] Epoch: 7 [DONE]                                                             \n",
      "[Training] Epoch: 7, LossG: 0.4176                                                                           \n",
      "[Validation] Epoch: 7 [DONE]                                                             \n",
      "[Validation] Epoch: 7, LossG: 0.4572                                                                         \n",
      "Best model saved at epoch 7\n",
      "[Training] Epoch: 8 [DONE]                                                             \n",
      "[Training] Epoch: 8, LossG: 0.3959                                                                           \n",
      "[Validation] Epoch: 8 [DONE]                                                             \n",
      "[Validation] Epoch: 8, LossG: 0.4804                                                                         \n",
      "No improvement in last epoch. Counter: 1\n",
      "[Training] Epoch: 9 [DONE]                                                             \n",
      "[Training] Epoch: 9, LossG: 0.3803                                                                           \n",
      "[Validation] Epoch: 9 [DONE]                                                             \n",
      "[Validation] Epoch: 9, LossG: 0.3997                                                                         \n",
      "Best model saved at epoch 9\n",
      "[Training] Epoch: 10 [DONE]                                                             \n",
      "[Training] Epoch: 10, LossG: 0.3749                                                                          \n",
      "[Validation] Epoch: 10 [DONE]                                                             \n",
      "[Validation] Epoch: 10, LossG: 0.3730                                                                        \n",
      "Best model saved at epoch 10\n",
      "[Training] Epoch: 11 [DONE]                                                             \n",
      "[Training] Epoch: 11, LossG: 0.3601                                                                          \n",
      "[Validation] Epoch: 11 [DONE]                                                             \n",
      "[Validation] Epoch: 11, LossG: 0.3925                                                                        \n",
      "No improvement in last epoch. Counter: 1\n",
      "[Training] Epoch: 12 [DONE]                                                             \n",
      "[Training] Epoch: 12, LossG: 0.3532                                                                          \n",
      "[Validation] Epoch: 12 [DONE]                                                             \n",
      "[Validation] Epoch: 12, LossG: 0.3489                                                                        \n",
      "Best model saved at epoch 12\n",
      "[Training] Epoch: 13 [DONE]                                                             \n",
      "[Training] Epoch: 13, LossG: 0.3475                                                                          \n",
      "[Validation] Epoch: 13 [DONE]                                                             \n",
      "[Validation] Epoch: 13, LossG: 0.3495                                                                        \n",
      "No improvement in last epoch. Counter: 1\n",
      "[Training] Epoch: 14 [DONE]                                                             \n",
      "[Training] Epoch: 14, LossG: 0.3400                                                                          \n",
      "[Validation] Epoch: 14 [DONE]                                                             \n",
      "[Validation] Epoch: 14, LossG: 0.3512                                                                        \n",
      "No improvement in last epoch. Counter: 2\n",
      "[Training] Epoch: 15 [DONE]                                                             \n",
      "[Training] Epoch: 15, LossG: 0.3381                                                                          \n",
      "[Validation] Epoch: 15 [DONE]                                                             \n",
      "[Validation] Epoch: 15, LossG: 0.3435                                                                        \n",
      "Best model saved at epoch 15\n",
      "[Training] Epoch: 16 [==========>    ] 71.4% Loss: 0.3327, CE: 0.0658, Dice: 0.95563060"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\julie\\OneDrive - ETS\\MTI865\\MTI865-Competition\\mainSegmentationChallenge.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/julie/OneDrive%20-%20ETS/MTI865/MTI865-Competition/mainSegmentationChallenge.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m BESTEPOCH \u001b[39m=\u001b[39m runTraining()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/julie/OneDrive%20-%20ETS/MTI865/MTI865-Competition/mainSegmentationChallenge.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m runTesting(BestEpoch\u001b[39m=\u001b[39mBESTEPOCH)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/julie/OneDrive%20-%20ETS/MTI865/MTI865-Competition/mainSegmentationChallenge.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m runEvaluation(BESTEPOCH)\n",
      "\u001b[1;32mc:\\Users\\julie\\OneDrive - ETS\\MTI865\\MTI865-Competition\\mainSegmentationChallenge.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/julie/OneDrive%20-%20ETS/MTI865/MTI865-Competition/mainSegmentationChallenge.ipynb#W6sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m images \u001b[39m=\u001b[39m to_var(images)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/julie/OneDrive%20-%20ETS/MTI865/MTI865-Competition/mainSegmentationChallenge.ipynb#W6sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m \u001b[39m################### Train ###################\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/julie/OneDrive%20-%20ETS/MTI865/MTI865-Competition/mainSegmentationChallenge.ipynb#W6sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39m#-- The CNN makes its predictions (forward pass)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/julie/OneDrive%20-%20ETS/MTI865/MTI865-Competition/mainSegmentationChallenge.ipynb#W6sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m net_predictions \u001b[39m=\u001b[39m net(images)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/julie/OneDrive%20-%20ETS/MTI865/MTI865-Competition/mainSegmentationChallenge.ipynb#W6sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m \u001b[39m#-- Compute the losses --#\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/julie/OneDrive%20-%20ETS/MTI865/MTI865-Competition/mainSegmentationChallenge.ipynb#W6sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m \u001b[39m# THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/julie/OneDrive%20-%20ETS/MTI865/MTI865-Competition/mainSegmentationChallenge.ipynb#W6sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m segmentation_classes \u001b[39m=\u001b[39m getTargetSegmentation(labels)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\segmentation_models_pytorch\\base\\model.py:32\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[0;32m     30\u001b[0m decoder_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(\u001b[39m*\u001b[39mfeatures)\n\u001b[1;32m---> 32\u001b[0m masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msegmentation_head(decoder_output)\n\u001b[0;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassification_head \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassification_head(features[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BESTEPOCH = runTraining()\n",
    "runTesting(BestEpoch=BESTEPOCH)\n",
    "runEvaluation(BESTEPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ae10184-bacf-4c4d-9767-3272a76a0052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the testing... ~~~~~~\n",
      "----------------------------------------\n",
      "~~~~~~~~~~~ Starting the testing ~~~~~~~~~~\n",
      "[Inference] Segmentation Done !                                                                              \n",
      "###                                                       ###\n",
      "###         TEST RESULTS                                  ###\n",
      "###  Dice : c1: 0.5687 (0.3683) c2: 0.7404 (0.2356) c3: 0.8610 (0.2595) Mean: 0.7233 (0.2878) ###\n",
      "###  HD   : c1: 23.9789 (19.4527) c2: 6.8428 (10.6456) c3: 4.5790 (8.2024) Mean: 11.8002 (12.7669) ###\n",
      "###  ASD  : c1: 7.3617 (7.6343) c2: 2.2034 (4.3106) c3: 1.4603 (3.1765) Mean: 3.6751 (5.0405) ###\n",
      "###                                                       ###\n"
     ]
    }
   ],
   "source": [
    "# runEvaluation(22)\n",
    "runTesting(BestEpoch=22)\n",
    "# runTesting(modelName='Model_loss_0_0190')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all ground truth images in the training and val sets, compute class distribution\n",
    "root_dir = './Data/'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_set = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                  root_dir,\n",
    "                                                  transform=transform,\n",
    "                                                  mask_transform=mask_transform,\n",
    "                                                  equalize=False)\n",
    "train_loader = DataLoader(train_set,\n",
    "                            batch_size=1,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                root_dir,\n",
    "                                                transform=transform,\n",
    "                                                mask_transform=mask_transform,\n",
    "                                                equalize=False)\n",
    "val_loader = DataLoader(val_set,\n",
    "                        batch_size=1,\n",
    "                        worker_init_fn=np.random.seed(0),\n",
    "                        num_workers=0,\n",
    "                        shuffle=False)\n",
    "\n",
    "class_distribution = np.zeros(4)\n",
    "for i, data in enumerate(train_loader):\n",
    "    images, labels, img_names = data\n",
    "    labels = to_var(labels)\n",
    "    images = to_var(images)\n",
    "    segmentation_classes = getTargetSegmentation(labels)\n",
    "    for j in range(4):\n",
    "        class_distribution[j] += torch.sum(segmentation_classes == j).item()\n",
    "\n",
    "for i, data in enumerate(val_loader):\n",
    "    images, labels, img_names = data\n",
    "    labels = to_var(labels)\n",
    "    images = to_var(images)\n",
    "    segmentation_classes = getTargetSegmentation(labels)\n",
    "    for j in range(4):\n",
    "        class_distribution[j] += torch.sum(segmentation_classes == j).item()\n",
    "\n",
    "class_distribution = class_distribution / np.sum(class_distribution)\n",
    "\n",
    "print('Class distribution: {}'.format(class_distribution))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
